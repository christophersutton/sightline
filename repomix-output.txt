This file is a merged representation of the entire codebase, combined into a single document.
Generated by Repomix on: 2025-02-08T02:26:18.810Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
_docs/
  archive/
    app-mvp-prd.md
    app-overview.md
    current_errors.txt
    gauntlet-project-overview.md
    GEO.md
    implementation-plan.md
    mvp-prd.md
    navplan.md
    technical-overview.md
    technical-requirements.md
  futures/
    content-gen/
      content-generation-prd.md
      content-genreation-technical-overview.md
  user-stories/
    1-landmark-detection.md
    10-metadata-extraction.md
    2-content-browsing.md
    3-location-details.md
    4-user-accounts.md
    5-save-places.md
    6-video-reviews.md
    7-auto-categorization.md
    8-upload-moderation.md
    9-non-landmark-detection.md
    index.md
  improve-camera.md
  navplan.md
  o3.xml
firebase/
  functions/
    .eslintrc.json
    .gitignore
    index.js
    package.json
  firebase.json
  firestore.indexes.json
  firestore.rules
  storage.rules
sightline/
  sightline/
    Assets.xcassets/
      AccentColor.colorset/
        Contents.json
      AppIcon.appiconset/
        Contents.json
      discoverbg.imageset/
        Contents.json
      Icon-1024.imageset/
        Contents.json
      ladybirdlake1.imageset/
        Contents.json
      nocontent.imageset/
        Contents.json
      profile-bg.imageset/
        Contents.json
      utcapitol1.imageset/
        Contents.json
      utcapitol2.imageset/
        Contents.json
      Contents.json
    Models/
      Content.swift
      Event.swift
      FilterCategory.swift
      Neighborhood.swift
      Place.swift
    Preview Content/
      Preview Assets.xcassets/
        Contents.json
    Services/
      AuthService.swift
      FirestoreError.swift
      FirestoreService.swift
      FirestoreService+TestData.swift
      ServiceContainer.swift
      VideoPlayerManager.swift
    sightline.xcdatamodeld/
      sightline.xcdatamodel/
        contents
      .xccurrentversion
    State/
      AppState.swift
      AppViewModel.swift
    Views/
      Components/
        AdaptiveColorButton.swift
        FloatingMenuButton.swift
        ScanningAnimation.swift
        ScanningTransitionView.swift
      ContentFeedView/
        ContentFeedView.swift
        ContentFeedViewModel.swift
      CameraView.swift
      ContentItemView.swift
      MainTabView.swift
      PlaceDetailView.swift
      ProfileView.swift
      SplashView.swift
      VerticalFeedView.swift
    DebugGalleryView.swift
    LandmarkDetection.swift
    sightlineApp.swift
  sightline.xcodeproj/
    xcuserdata/
      chrissutton.xcuserdatad/
        xcdebugger/
          Breakpoints_v2.xcbkptlist
        xcschemes/
          xcschememanagement.plist
  sightlineTests/
    sightlineTests.swift
  sightlineUITests/
    sightlineUITests.swift
    sightlineUITestsLaunchTests.swift
.gitignore
.markdownlint.json

================================================================
Files
================================================================

================
File: _docs/archive/app-mvp-prd.md
================
# MVP PRD: In-the-Moment Short-Form Video Tour Guide

## 1. Overview & Objectives
### Purpose:
Provide users with immediate, location-based travel tips and recommendations via short-form videos, using a gamified "treasure hunt" approach where users unlock content by discovering and documenting landmarks.

### Objectives:
- Deliver an engaging "discover and unlock" experience centered around landmarks
- Build a self-sustaining content ecosystem through user contribution incentives
- Validate core AI/ML features for landmark detection and content categorization
- Create a clear path to monetization through premium city guides ("treasure maps")

## 2. Core User Flows & Stories

### A. Discovery & Unlock Flow
**User Story:**
As a traveler, I discover new areas by finding landmarks, either through organic exploration or guided treasure maps. Each landmark I find unlocks local recommendations and creates opportunities to contribute my own content.

**Key Flow:**
1. User encounters landmark → Opens app → Points camera
2. Landmark detection triggers content unlock
3. User views local recommendations
4. Option to purchase full city guide or unlock through contribution

### B. Content Creation & Rewards
**User Story:**
As a user, I can create short-form video recommendations and earn expanded access to the platform based on my contributions.

**Key Flow:**
1. Create and submit video content for a location
2. AI processes video for categorization and moderation
3. Upon approval, user earns unlock credits:
   - Single quality video → Unlock nearby landmarks
   - Three videos → Unlock district
   - Five quality videos → Unlock full city

### C. Premium Treasure Maps
**User Story:**
As a tourist planning my trip, I can purchase curated city guides that show me where to find the best content and optimal routes for exploration.

**Key Flow:**
1. Browse available city guides
2. Preview landmark locations and content types
3. Purchase guide
4. Access suggested routes and full landmark map

## 3. Technical & AI/ML Components

### A. Core Features
- **Landmark Detection:**
  - Google Landmark Detection API for identifying landmarks
  - Scene understanding for broader context
  - Location validation and mapping

- **Content Processing:**
  - Automated categorization and tagging
  - Quality assessment for reward eligibility
  - Speech-to-text for searchability
  - Content moderation

### B. User Authentication & Permissions
- Anonymous authentication for basic features
- Progressive account creation for content submission
- Clear permission messaging for camera usage

### C. Technical Architecture
- **Backend:**
  - Firebase for authentication and storage
  - Cloud Functions for AI/ML processing
  - Caching for frequently accessed landmarks

- **Frontend:**
  - Optimized camera integration
  - Smooth transitions between modes
  - Interactive map overlays for treasure maps

## 4. Content Strategy

### A. Initial Content Seeding
- Partner with select local guides for initial city coverage
- Focus on high-traffic landmarks and tourist areas
- Establish content guidelines and quality benchmarks

### B. User-Generated Content
- Clear contribution guidelines
- Quality control through AI and user validation
- Reward system for consistent contributors

### C. Premium Content
- Curated city guides with optimal routes
- Special access to hidden gems
- Enhanced content from verified creators

## 5. Monetization Strategy

### A. Freemium Model
- Basic landmark detection and content viewing free
- Unlock premium features through:
  1. Direct purchase of city guides
  2. Content contribution
  3. Community participation

### B. Premium Features
- Full city landmark maps
- Suggested exploration routes
- Offline access
- Advanced filtering and search

## 6. Next Steps & Investigations

### A. Technical Validation
- Prototype landmark detection accuracy
- Test content processing pipeline
- Validate unlock/reward mechanics

### B. Content Operations
- Establish initial creator partnerships
- Define content guidelines
- Create quality assessment criteria

### C. User Experience
- Design treasure map interface
- Prototype unlock animations
- Test reward messaging

### D. Metrics & Success Criteria
- Define key engagement metrics
- Set quality benchmarks for UGC
- Establish conversion targets

================
File: _docs/archive/app-overview.md
================
# Sightline App Overview

## Vision
Sightline transforms urban exploration through a gamified "treasure hunt" experience where users:
- Unlock location-based content by discovering landmarks
- Build a crowdsourced knowledge base through video contributions
- Earn access to premium features via content creation
- Access curated city guides ("Treasure Maps") with optimal exploration routes

## Architecture Overview
- **Frontend:**  
  - **Platform:** iOS  
  - **Language/Framework:** Swift Native (chosen for superior camera integration, real-time performance, and native UI components).
- **Backend:**  
  - **Platform:** Firebase  
  - **Services:**  
    - Authentication (starting with anonymous sessions and upgrading to full user accounts)
    - Real-time data synchronization
    - Cloud Functions supporting AI integrations for content categorization and moderation

- **Monorepo Organization:**  
  - `/ios` – Contains the Swift native iOS project.
  - `/firebase` – Contains Firebase Cloud Functions, authentication configurations, and other backend setups.
  - `/content-gen` – Bun-powered service for:
    - AI video processing pipelines
    - Treasure map generation algorithms
    - Reward system automation

## Key Features for MVP & Beyond
- **Gamified Discovery Engine:**
  - Landmark detection unlocks local video feeds
  - Progressive access system (landmark → district → city)
  - "Treasure Map" guided tours 

- **User-Generated Content Ecosystem:**
  - Contribution rewards system:
    - 1 quality video → Unlock nearby landmarks
    - 3 videos → District access
    - 5 videos → Full city unlock
  - AI-powered quality assessment and moderation

- **Monetization Infrastructure:**
  - Freemium model with premium city guides
  - Tiered access through:
    - Direct purchases
    - Content contributions
    - Community participation

## Roadmap
- **MVP (2 Weeks):**
  - Implement core discovery features and the landmark-triggered video feed.
  - Set up Firebase backend for authentication, real-time sync, and server-side processing via Cloud Functions.
  - Implement user video recording / review recording
  - Integrate AI services for content categorization and basic content moderation.
  
- **Phase 2 (Next 6 Months):**
  - Implement treasure map marketplace
  - Develop AR route guidance
  - Launch contributor reward programs
  - Introduce premium subscription tiers

- **Long-Term Vision:**
  - Crowdsourced city reputation system
  - Local business partnerships via promoted content
  - Cross-city exploration challenges
  - Advanced AI features:
    - Predictive content recommendations
    - Dynamic difficulty adjustment for treasure hunts
    - Multi-landmark combo rewards

================
File: _docs/archive/current_errors.txt
================
1. Command SwiftCompile failed with nonzero exit code

2. FirestoreService:
   - Reference to generic type 'FirestoreQuery' requires arguments in <...>
   - Reference to generic type 'FirestoreQuery' requires arguments in <...>
   - No 'async' operations occur within 'await' expression
   - No 'async' operations occur within 'await' expression

3. ContentFeedViewModel:
   - Cannot convert value of type 'Int' to expected argument type 'String'
   - Cannot convert value of type 'Int' to expected argument type 'String'

4. ContentItemView:
   - Call to main actor-isolated initializer 'init()' in a synchronous nonisolated context
   - Calls to initializer 'init()' from outside of its actor context are implicitly async

================
File: _docs/archive/gauntlet-project-overview.md
================
ReelAI
Reimagining TikTok With AI
Background
TikTok transformed how we view, share, and edit videos online. Not only did they pioneer short-form video, but they also made content creation more accessible to the masses through CapCut. The algorithm they created made "going viral" easier for even the new creator. You were no longer beholden to followers or subscribers - good content could reach the masses solely based on its quality.
But TikTok emerged in a pre-AI world. What if we could reimagine the platform with today's AI capabilities from the ground up? Instead of users spending hours editing videos, writing captions, or finding trending sounds, AI could transform raw ideas into engaging content. Rather than manually searching for content, AI could understand exactly what entertains each user. Today, we're rebuilding TikTok from an AI-first perspective, where intelligent agents enhance every aspect of creation and consumption.
Project Overview
This two-week project challenges you to rebuild and reimagine TikTok with AI, while leveraging modern AI tools and capabilities throughout the development process.
Week 1: Rapid Development (Due February 7 by 6 PM CST)
Use AI-first development tools (Cursor, Lovable, v0, Replit, or Windsurf) to rapidly build a functioning TikTok clone. This week focuses on practicing how AI can accelerate the development of enterprise-scale applications. Your goal is to create a solid foundation that you can enhance in Week 2.
Week 2: AI Innovation (Due February 14 by 6 PM CST)
Transform your clone by integrating AI features that enhance how users create, consume, and interact with content. With a working application as your foundation, you'll explore how AI can revolutionize the social video experience.
Submission Guidelines
At the end of each week, you’ll need to submit the following to the GauntletAI LMS:
A link to your project’s public GitHub repository.
A link to the brainlift you used to learn, understand, and enhance the application with AI.
A 5-minute walkthrough showcasing what you’ve built (and, where relevant, how you built it).
A link to a post on X or LinkedIn showcasing what you’ve built. 
A link to the working deployed application.
Week 1: Rapid Development (Due February 7 by 6 PM CST)
Your first week focuses on building a streamlined version of TikTok using AI development tools. Choose one user type and build a complete experience for them.


Choose Your Primary User
Content Creator: Users who make and share videos
Content Consumer: Users who discover and engage with content


Specify Your Niche
Narrow your focus to a specific type of user within your chosen category:
Creator Examples:
Fitness Coach sharing workout routines
Chef demonstrating recipes
Educator teaching concepts
Musician sharing performances
Beauty expert creating tutorials
Consumer Examples:
Fitness enthusiast looking for workouts
Home cook seeking new recipes
Student learning new topics
Music fan discovering new artists
Beauty enthusiast learning techniques


Define User Stories
Create detailed user stories for your specific user. For example:
Fitness Creator Stories:
"As a fitness coach, I want to add exercise timestamps to my workout videos"
"As a fitness coach, I want to tag videos with difficulty levels"
"As a fitness coach, I want to categorize videos by muscle group"
Recipe Consumer Stories:
"As a home cook, I want to save recipes by cuisine type"
"As a home cook, I want to filter videos by cooking time"
"As a home cook, I want to create collections of weeknight dinner ideas"


Build Vertically
Build complete features for your specific user type. Each feature should work end-to-end before moving to the next.
For example, if you choose Creator:
✅ Complete video upload → processing → publishing pipeline
❌ Partial implementation of comments, likes, AND sharing
If you choose Consumer:
✅ Complete video feed → view → interaction flow
❌ Partial implementation of profile, search, AND notifications
Remember: A fully functional app for one user type is more valuable than a partial implementation trying to serve both.


To pass week 1, you must:
Build and deploy a working vertical slice
Pick either creator or consumer
Pick a niche within your choice
Identify 6 user stories you are aiming to ship for the niche
Showcase your functionality in your video and code
Highlight your path, niche, and user stories in your walkthrough video
Show working functionality that matches the 6 user stories you picked earlier


Week 2: AI Innovation (Due February 14 by 6 PM CST)
Your second week focuses on enhancing your vertical slice with AI features that meaningfully improve the user experience.


Understand Features vs. User Stories 
An AI Feature is a major capability that solves a user problem. Each feature enables multiple User Stories - specific ways users interact with that feature to achieve their goals.
Choose Your AI Features Select 2 AI features that:
Address real problems for your chosen user type
Integrate naturally with your Week 1 implementation
Create significant value for your niche


Define User Stories 
Create at least 6 user stories across your chosen features. For example:
Creator Example:
Feature: SmartEdit
"As a creator, I can say 'remove awkward pause' and AI edits out silence"
"As a creator, I can say 'zoom on product' and AI adds zoom effects"
"As a creator, I can say 'enhance lighting' and AI adjusts dark scenes"
Feature: TrendLens
"As a creator, I get AI suggestions for optimal video length"
"As a creator, I receive trending hashtag recommendations"
Consumer Example:
Feature: SmartScan
"As a recipe learner, I can ask 'show sauce-making part' and jump there"
"As a recipe learner, I can search for specific techniques shown"
"As a recipe learner, I can find moments where ingredients are listed"
Feature: PersonalLens
"As a recipe learner, I get recommendations based on my skill level"
"As a recipe learner, I see content matched to my learning pace"


Build Vertically
Build complete features for your specific user type. Each feature should work end-to-end before moving to the next.


To pass Week 2, you must:
Implement 2 substantial AI Features
Define at least 6 User Stories across your features
Show working functionality that matches these user stories in your video


Important Technical Decisions (ITDs)
Our recommended stack includes Firebase Auth, Cloud Storage, Firestore, Generative AI in Firebase, Cloud Functions, Cloud Messaging, and App Hosting—with native deployment using Kotlin for Android or Swift for iOS. 
1. Firebase Auth
Purpose:
 Provide secure user authentication and account management.
Usage:
Enable sign-up, login, and session management for both content creators and consumers.
Support social logins (Google, Facebook, etc.) to streamline user onboarding.
2. Firebase Cloud Storage
Purpose:
 Store and serve media assets reliably.
Usage:
Manage video file uploads, thumbnails, and other media.
Integrate with Cloud Functions to process or transform media assets before final storage.
3. Firestore
Purpose:
 Serve as the primary NoSQL database for real-time data management.
Usage:
Store metadata such as video descriptions, timestamps, comments, likes, and user profiles.
Provide real-time synchronization of data between the server and client, ensuring a seamless user experience.
4. Generative AI in Firebase
Purpose:
 Integrate advanced AI capabilities directly into the Firebase ecosystem.
Usage:
Leverage generative AI (via Firebase Cloud Functions and external AI APIs) to automate content enhancements (e.g., auto-captioning, smart editing commands).
Enable new AI-driven features like content recommendations or automated video effects.
5. Cloud Functions Firebase
Purpose:
 Implement serverless backend logic.
Usage:
Handle video processing, trigger AI enhancements, and integrate securely with external APIs.
Offload compute-intensive tasks from the client, ensuring scalability and maintainability.
6. Cloud Messaging
Purpose:
 Provide real-time notifications and updates to users.
Usage:
Send push notifications for new content, comments, likes, or AI-generated suggestions.
Enhance user engagement by keeping them informed about relevant interactions or updates.
7. App Distribution on Firebase
Purpose:
 Deploy and host the application reliably.
Usage:
Use Firebase Hosting for mobile components to ensure fast global content delivery.
Leverage Firebase’s integration capabilities to streamline updates and maintain uptime.
8. OpenShot Video Editing API
Purpose:
 Manage video editing using an open source API hosted on AWS.
Usage:
Use OpenShot to edit and process video files programmatically.
Leverage OpenShot’s features—including trimming, transitions, and effects—to automate and customize video production workflows.
9. Native Mobile Development – Kotlin or Swift
Purpose:
 Develop a platform-specific mobile application.
Usage:
Recommended: Choose either Kotlin (for Android) or Swift (for iOS) and focus on that platform to ensure depth and quality of implementation.
Alternative: Build a cross-platform app using something like Flutter.
Integrate Firebase SDKs for authentication, data storage, messaging, and more, ensuring a smooth, native experience on your chosen platform.


Test2Pass (T2P) requirements
Brainlift
You must submit a Brainlift that highlights any SpikyPOVs that guided you in choosing AI features for your video platform.
Walkthrough Video
You must screen share and walkthrough your application in a 5 min video. The video must showcase your AI features functioning and highlight how you went about setting up evaluations for these features on LangSmith/LangFuse.
GitHub Repository
You must submit the repository with the code associated with your project submission.
Deployed Application
You must submit a link to the deployed application, where graders can login and try out your AI features.
To pass week 1, you must:
Build and deploy a working vertical slice
Pick either creator or consumer
Pick a niche within your choice
Identify 6 user stories you are aiming to ship for the niche
Showcase your functionality in your video and code
Highlight your path, niche, and user stories in your walkthrough video
Show working functionality that matches the 6 user stories you picked earlier
Build a mobile application natively using Kotlin or Swift
AI Tools and Resources


The architecture for a mobile video platform requires careful planning. You can draw inspiration from modern video apps like TikTok, Instagram Reels, and YouTube Shorts, while leveraging the provided OpenShot API for video processing capabilities.
Milestones
Completion date
Project phase
Description
 Feb 5, 2025
Application MVP
2-3 cohesive user stories complete
 Feb 7, 2025
TikTok Rebuild Complete
6 or more cohesive user stories complete
 Feb 9, 2025
Week 1 Resubmission
Can resubmit to showcase progress
 Feb 10, 2025
AI Objectives Start


 Feb 12, 2025
Week 2 Check-in


 Feb 14, 2025
AI Features Complete
2 large AI features working seamlessly

================
File: _docs/archive/GEO.md
================
Neighborhood-Based Content System Implementation

Implementation Goal:
Transition from Knowledge Graph API to Geocoding API for neighborhood-based content unlocking using Google's place_id as stable identifiers.
Key Changes Required:
1. Cloud Function (annotateImage):
Replace Knowledge Graph calls with Geocoding API reverse lookup
Return neighborhood data with place_id, bounds, and name
2. Firestore Structure:
Add neighborhoods collection with place metadata
Track user unlocks via unlocked_neighborhoods subcollection
Link content to neighborhoods via place_id arrays
3. iOS Modifications (LandmarkDetection.swift):
Update LandmarkInfo to store neighborhood place_id and bounds
Implement neighborhood unlocking on detection
Modify content queries to filter by unlocked place_ids
4. Fallback System:
Generate 6-character geohash zones when no neighborhood found
Treat geohash zones as temporary neighborhoods
Critical Requirements:
Use Google's place_id as primary neighborhood identifier
Maintain neighborhood metadata cache in Firestore
Handle content->neighborhood relationships at creation time
Support both precise neighborhoods and approximate geohash zones
First Files to Modify:
1. firebase/functions/index.js (Cloud Function)
2. sightline/LandmarkDetection.swift (iOS Model/View)



1. Core Architecture Data Flow

Landmark Detection → Geocoding API → Firestore → Content Unlocking

---

2. Backend Modifications

Cloud Function Additions

```js
// In annotateImage cloud function
async function getNeighborhoodFromCoords(lat, lng) {
const response = await mapsClient.reverseGeocode({
params: {
latlng: ${lat},${lng},
result_type: ['neighborhood'],
key: API_KEY
}
});
return response.data.results
.filter(r => r.types.includes('neighborhood'))
.map(r => ({
place_id: r.place_id,
name: r.address_components[0].long_name,
bounds: r.geometry.bounds
}));
}
```

---

3. Firestore Structure Neighborhoods Collection

```js
// /neighborhoods/{place_id}
{
name: "Capitol District",
place_id: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
bounds: {
ne: { lat: 30.2797, lng: -97.7354 },
sw: { lat: 30.2717, lng: -97.7445 }
},
geohash: "9v6yex1"
}
```

User Unlocks

```js
// /users/{uid}/unlocked_neighborhoods/{place_id}
{
first_unlocked: Timestamp,
last_accessed: Timestamp,
detection_count: number
}
```

---

4. iOS Implementation Updated Landmark Model

```swift
struct Neighborhood {
let placeID: String
let name: String
let bounds: GeoBounds
}
struct GeoBounds {
let northeast: CLLocationCoordinate2D
let southwest: CLLocationCoordinate2D
}
```

Unlocking Logic

```swift
func handleLandmarkDetection( landmark: LandmarkInfo) {
guard let location = landmark.location else { return }
Firestore.firestore().collection("users")
.document(uid)
.collection("unlocked_neighborhoods")
.document(neighborhood.placeID)
.setData([
"name": neighborhood.name,
"bounds": [
"ne": GeoPoint(latitude: neighborhood.bounds.ne.lat,
longitude: neighborhood.bounds.ne.lng),
"sw": GeoPoint(latitude: neighborhood.bounds.sw.lat,
longitude: neighborhood.bounds.sw.lng)
]
], merge: true)
}
```

---

5. Content Querying Fetch Unlocked Content

```js
func fetchContentForUser( userId: String) async throws -> [Content] {
let unlockedRefs = getUnlockedNeighborhoodIDs()
return try await Firestore.firestore().collection("content")
.whereField("neighborhoodIDs", arrayContainsAny: unlockedRefs)
.order(by: "timestamp", descending: true)
.limit(to: 50)
.getDocuments()
.documents
.compactMap { try $0.data(as: Content.self) }
}
```

---

6. Fallback System Geohash Handling

```js
// When no neighborhood found:
let geohash = Geohash.encode(lat: location.lat, lng: location.lng, precision: 6)
Firestore.firestore().collection("neighborhoods")
.document(geohash)
.setData([
"type": "geohash",
"center": GeoPoint(latitude: location.lat, longitude: location.lng),
"radius_m": 1000
])
```

---

================
File: _docs/archive/implementation-plan.md
================
# Detailed Implementation Plan

## Overview

This plan outlines the step-by-step approach for building the Sightline MVP over three phases, corresponding to the user stories. Each phase includes specific tasks, manual configuration steps, and simple error handling strategies.

## Phase 1: Core App Features

### 1. Project Setup
- Create a new Swift project
- Initialize a new Firebase project
- Link the iOS app to Firebase via CocoaPods or Swift Package Manager
- Configure Firebase console:
  - Authentication (enable Anonymous Authentication)
  - Firestore database (with development rules)
  - Cloud Functions (for AI processing)
  - Cloud Storage

### 2. Landmark Detection
- Request camera permissions in the app's Info.plist
- Implement a camera view controller to stream video
- Integrate the Google Landmark API to detect landmarks
- Provide real-time visual feedback during detection
- Save detected "unlocked" neighborhoods in local storage (using Core Data or similar)
- On detection failure, display a user-friendly error message with an option to retry

### 3. Content Browsing
- Design a UI view that displays a video feed
- Fetch video URLs from Firebase Storage
- Integrate a video player component for smooth playback
- If video loading fails, show an alert with a retry option

### 4. Location Details
- Use the Google Places API to fetch and display location details
- Display a static map image using the Google Maps Static API
- Enable deep links to external maps for navigation
- Provide a simple error message with a retry option if location data fails to load

## Phase 2: User Accounts & Video Reviews

### 1. User Accounts
- Implement Firebase anonymous authentication
- Create a UI flow for account upgrade (email or social signup)
- Migrate any necessary local data from the anonymous session
- Display error messages with a retry option for authentication issues

### 2. Save Places
- Add a toggle control to save or unsave locations
- Persist saved locations using Firebase or local state management
- On failure, display an error message and prompt a retry

### 3. Video Reviews
- Integrate in-app video recording using native iOS APIs
- Implement video upload to Firebase Storage
- Associate the video with location data (using the Google Places API)
- If upload fails, show a clear error message with a retry option

## Phase 3: AI Features

### 1. Auto-Categorization
- Integrate a speech-to-text service for video audio analysis
- Automatically generate tags based on the extracted text
- Display the tags for user review with the option for manual editing

### 2. Upload Moderation
- Implement basic content moderation during video upload
- If a violation is detected, block the upload and display a friendly error message

### 3. Metadata Extraction
- Use entity extraction techniques to pull key details (e.g., business hours, price range)
- Present the extracted metadata to the user for confirmation and allow corrections

### 4. Non-Landmark Detection Fallback
- If the Google Landmark API fails to detect a landmark, invoke the MLLM (OpenAI GPT-4 Vision) fallback
- Display the confidence level of the fallback result
- Allow the user to confirm or retry detection if necessary

================
File: _docs/archive/mvp-prd.md
================
# MVP PRD: Sightline

## Objectives
- Deliver a seamless, short-form video experience driven by local content.
- Use landmark detection as a strategic trigger to unlock a curated video feed for a given area.
- Incorporate AI-driven categorization and content moderation to ensure content relevance and quality.
- Utilize Firebase services for authentication, real-time synchronization, and backend processing.

## Core User Flows (Based on MVP User Stories)
1. **Discovery & Feed Unlock Flow:**
   - **Landmark Detection as the Hook:**  
     The app's native camera continuously scans for landmarks. When a landmark is detected, it isn't the final destination—instead, it unlocks a curated feed of short-form videos from the surrounding area.
   - **Content Feed Display:**  
     The feed shows locally relevant, AI-curated videos that capture the essence of the area, inviting users to explore more content and engage with the community.
   - **Engagement Opportunities:**  
     Users can interact with videos, save favorites, or engage in actions that may unlock additional features or premium content in the future.

2. **Anonymous Authentication & Account Upgrade:**
   - **Seamless Onboarding:**  
     Users begin with Firebase's anonymous authentication for frictionless access to content.
   - **Transition to Full Accounts:**  
     When users decide to save content, post, or access additional features, they can seamlessly upgrade their anonymous account to a full profile. Data migration is managed automatically through Firebase linking mechanisms.

3. **Video Playback & User Interaction:**
   - **Native Video Playback:**  
     A high-performance video player ensures smooth playback of short-form content.
   - **Engagement and Navigation:**  
     Although the initial trigger is landmark detection, the main interface focuses on an engaging video feed with intuitive user interactions for swiping, liking, and sharing content.

4. **AI Categorization & Content Moderation:**
   - **Content Analysis:**  
     As videos are uploaded or streamed, Firebase Cloud Functions call external AI services (e.g., Google Cloud Vision or custom ML endpoints) to analyze and categorize the content based on local relevance.
   - **Moderation Pipeline:**  
     A built-in moderation mechanism assesses video quality and flags content that does not meet quality or safety standards. This ensures the feed remains engaging and trustworthy.
   - **Integration & Error Handling:**  
     AI processing is tightly integrated with the backend using Cloud Functions, ensuring robust error handling, fallback strategies, and minimal processing latency.
   - **Extract structured metadata (business hours, price ranges) using vision-language models**
   - **Implement fallback MLLM analysis when Google Landmark API fails**

## Technical Considerations
- **iOS App (Swift Native):**  
  - Leverages robust native camera frameworks for real-time landmark detection.
  - Uses local caching (via Core Data or equivalent) to support smooth offline experiences and temporary data storage.
  - Provides integration hooks for forwarding video metadata and images to Firebase Cloud Functions for AI processing.
- **Firebase Backend:**
  - **Authentication:**  
    Implements a fluid transition from anonymous authentication to full user accounts, ensuring data integrity during the transition.
  - **Cloud Functions:**  
    Hosts essential functions that perform AI-based categorization and moderation, interfacing with external AI services and managing processing errors.
  - **Data Sync:**  
    Ensures real-time synchronization of the video feed and user activity, maintaining a responsive content delivery pipeline.
- **AI/ML Pipeline (MVP Level):**
  - Incorporates external AI services to identify, categorize, and moderate content.
  - Focuses on delivering immediate, relevant feedback for content uploads while ensuring an efficient and responsive user experience.
  - **Implement confidence scoring for location detection results**
  - **Create error recovery flows for failed video uploads**
  - **Establish Firebase Storage rules for user-generated content**

## Out of Scope (for MVP)
- Development of an advanced content generation pipeline (covered under future stretch goals in `/content-gen`).
- Extended analytics, cross-platform user interfaces, and complex offline caching beyond basic requirements.

================
File: _docs/archive/navplan.md
================
# Updated Navigation Implementation Plan

This document outlines the detailed plan to implement dual-mode navigation for our app—one with a vertically scrolling feed for broad content exploration (with TikTok-like snapping, preloading, and smart audio transitions) and a horizontally swipeable Place Details view for exploring reels specific to a given place. In addition, the plan covers enhanced navigation for switching neighborhoods and categories.

---

## 1. Overview

The goal is to deliver a seamless, modern user experience by supporting two distinct interaction models:

- **Vertical Feed (Broad Exploration):**  
  Users scroll vertically through a list of reels. Videos should start preloading and begin playback as soon as they are in (or near) the viewport. As the user scrolls, snapping behavior ensures that a reel "locks" into place, and audio mixing immediately mutes or reduces the outgoing video's audio even if the snap isn't complete.

- **Place Details View (In-Depth Exploration):**  
  When a reel's pill button (which displays the place name) is tapped, the app navigates to a Place Details view. This view features a fixed header displaying the place information (name, address, etc.) and a horizontally swipeable carousel underneath to navigate between reels about that place.

- **Neighborhood & Category Navigation:**  
  The top section of the content feed will include two horizontally scrollable selectors for neighborhoods and categories. These selectors update the feed when changed and need to do so in a smooth, non-jarring manner.

---

## 2. Overall Architecture and State Management

- **Navigation:**  
  - Wrap `MainTabView` with a `NavigationStack` to enable deep navigation
  - Define navigation destination enum:
    ```swift
    enum NavigationDestination: Hashable {
        case placeDetail(placeId: String, initialContentId: String)
    }
    ```
  - Enhance `AppState` to include navigation path management

- **State Management:**  
  - Extend existing `ContentFeedViewModel` rather than creating new ones:
    - Add video preloading coordination
    - Add scroll position and snap state management
    - Add audio transition management
  - Create a new `PlaceDetailViewModel` for place-specific state

- **Video Player Management:**
  - Build upon existing `AVQueuePlayer` + `AVPlayerLooper` implementation
  - Add preloading manager to handle multiple `AVPlayer` instances:
    - Maintain pool of 3-4 preloaded players maximum
    - Implement cleanup strategy for unused players
  - Coordinate audio transitions between players during scroll

---

## 3. Vertical Feed Implementation

### Layout & Scrolling Behavior
- **Feed Construction:**  
  - Replace current horizontal `TabView` in `ContentFeedView` with `ScrollView`
  - Maintain existing `ContentItemView` structure but adapt for vertical layout
  - Add scroll position monitoring using `GeometryReader`
  
- **Snapping Mechanism:**  
  - Implement custom scroll view coordinator to handle snap behavior
  - Use `ScrollViewReader` for programmatic scrolling
  - Maintain smooth video playback during snap transitions

### Video Preloading and Audio Control
- **Enhanced ContentItemViewModel:**
  - Add preloading state management
  - Maintain existing looping behavior during playback
  - Add volume control for cross-fade support

- **Preloading Strategy:**
  - Preload maximum 2 videos ahead and 1 behind current position
  - Implement memory-aware cleanup of distant preloaded content
  - Maintain existing video cleanup pattern from `ContentItemViewModel`

---

## 4. Place Details View Implementation

### Layout
- **Header:**  
  - Create a fixed header at the top of the `PlaceDetailView` that displays the place's name, address, and other pertinent details.
  
- **Horizontal Reel Carousel:**  
  - Below the header, implement a horizontally swipeable carousel using a `TabView` with the `.page` style.
  - Each cell in this carousel will display content similarly to `ContentItemView`; however, it can optionally share state (or simply restart video playback) to ensure smooth transitions.

### Transition from the Feed
- **Navigation Trigger:**  
  - Update `ContentItemView` with an overlay "pill" button. This button should be wrapped in a `NavigationLink` (or trigger programmatic navigation via the `NavigationStack` path) that pushes the Place Details view.
  
- **Seamless Context Passing:**  
  - Pass along the necessary place data (or an identifier to fetch data) and, if possible, any relevant video playback context to ensure a smooth transition between the broad feed and detail view.

---

## 5. Neighborhood and Category Filtering

### Interaction Model
- **Selectors:**  
  - At the top of the vertical feed, implement two horizontal scroll selectors:
    - **Neighborhood Selector:** Displays available neighborhoods. Tapping a neighborhood updates the active selection in the view model.
    - **Category Selector:** Shows content categories (e.g., Restaurants, Events). Changes update the feed state accordingly.
  
- **Smooth Transitions:**  
  - Implement smooth animations on selection change.
  - Consider debouncing input if rapid selection could trigger heavy content reloads.
  - Ensure that changing either filter instantly updates the content area while showing a temporary loading indicator if needed.

### State Synchronization
- Enhance `ContentFeedViewModel` with functions that:
  - Handle neighborhood and category changes by refreshing the content feed smoothly.
  - Optionally preload adjacent content based on the new selection.
  - Keep the UI responsive by offloading heavy data fetching to background tasks controlled via async/await.

---

## 6. Integration & Detailed State Management

### Video Player Coordination
- **Player Pool Management:**
  ```swift
  class VideoPlayerPool {
      private var preloadedPlayers: [String: AVQueuePlayer] // keyed by content ID
      private let maxPreloadedPlayers = 4
      
      func preloadVideo(for contentId: String)
      func cleanupDistantPlayers()
  }
  ```

- **Audio Transition Handling:**
  - Implement volume ramping between players
  - Maintain existing mute state management
  - Add cross-fade duration configuration

### Memory Management
- **Resource Limits:**
  - Set maximum of 4 preloaded videos at any time
  - Implement aggressive cleanup of unused video resources
  - Add memory pressure handling

- **Performance Monitoring:**
  - Add video preload time tracking
  - Monitor memory usage during scroll operations
  - Implement adaptive preloading based on device capabilities

### NavigationStack Integration
- **Global Navigation Setup:**  
  - Wrap the main content views (`ContentFeedView`, `PlaceDetailView`, etc.) in a `NavigationStack` linked to a global navigation path (e.g., maintained in `AppState`).
  
- **Navigation Destinations:**  
  - Define explicit navigation destinations so that tapping on the pill button in any reel cleanly pushes the Place Detail view.

### Video Playback & Preloading Coordination
- **Centralized Control:**  
  - Consider a shared video player state in the view model (or even a dedicated controller) to help manage preloading, volume transitions, and playback continuity between cells.
  
- **Async Coordination:**  
  - Utilize async methods or Combine pipelines to handle asynchronous loading of video content, ensuring that preloading and audio adjustments trigger reliably based on scroll events and snapping detection.

---

## 7. Testing & Performance Optimization

- **Unit & UI Testing:**  
  - Test the snapping logic using simulated scroll events.
  - Validate that preloading and audio transitions occur as expected through unit tests on the view models.
  - Manually test transitions between neighborhoods/categories to monitor for jank.

- **Performance Profiling:**  
  - Check memory usage during heavy scrolling to ensure that the preloading of videos does not leak resources.
  - Profile the responsiveness of the vertical feed to determine if further optimizations (or a shift to a more complex UICollectionView wrapper) become necessary.

---

## Conclusion

This updated plan details a dual-mode navigation structure that leverages both a TikTok-inspired vertical feed and a horizontally swipeable details view. It incorporates smart preloading, proactive audio control, and smooth transitions for neighborhood and category changes—all managed by a robust state management solution under a modern `NavigationStack` framework.

This plan should provide a clear roadmap for implementation. The focus is on delivering a smooth, responsive, and modern UX for the demo, even if that necessitates more complex state management to keep everything in sync.

================
File: _docs/archive/technical-overview.md
================
# Technical Architecture PRD: Local Video Guide MVP

## 1. System Overview

### A. iOS Mobile App
Primary user-facing application for landmark detection and content viewing.

Tech Stack Decision Points (Updated):
1. **Swift Native** confirmed for:
   - Direct camera hardware access
   - Native MapKit integration
   - Firebase iOS SDK compatibility
   - Future ARKit expansion

### B. Firebase Backend Services
Core infrastructure components:
1. **Authentication**  
   - Anonymous sessions → Full accounts
   - Social login providers
   - Secure token handling

2. **Firestore Database**  
   - Real-time content sync
   - User preference storage
   - Landmark metadata

3. **Cloud Functions**  
   - AI processing pipeline
   - Content moderation
   - Third-party API orchestration

4. **Cloud Storage**  
   - Video upload/processing
   - Asset versioning
   - CDN delivery
   - Static map image storage

5. **Cloud Functions (New Section)**
   - Map image generation via Google Maps Static API
   - Deep link URL construction
   - Landmark location validation

## 2. iOS App Architecture (Updated)

### A. Core Components
1. **Camera System**
   - Frame capture → Firebase Vision preprocessing
   - Landmark detection pipeline:
     1. Google Landmark Detection API (primary)
     2. MLLM visual analysis fallback
     3. Confidence scoring system

2. **Content Player**
   - Firebase Storage video streaming
   - Offline caching strategy
   - Category management via Firestore

3. **Location Interface**
   - Static map images generated server-side
   - Landmark coordinates with deep links:
     - `maps://` for Apple Maps
     - `https://www.google.com/maps` for Google Maps
   - Tap-to-navigate functionality
   - Cached map tiles for offline use

### B. Data Models (Updated)

```swift
struct Landmark {
    let id: String
    let name: String
    let coordinates: GeoPoint
    let staticMapURL: String // Pre-rendered map image
    let directionsDeepLink: String // maps:// or googlemaps:// URL
    let detectionMetadata: [String: Any]
    let mllmFallbackAnalysis: String?
}

struct Content {
    let id: String
    let firebasePath: String
    let moderationStatus: ModerationStatus
    let aiMetadata: [String: Any] // Extracted entities
    let unlockRequirements: UnlockTier
}
```

## 3. AI/ML Integration

### A. Processing Pipeline
1. **Client-Side**  
   - Frame preprocessing
   - Basic object detection
   - Network optimization

2. **Cloud Functions**

```typescript
   export processContent = functions.storage.object().onFinalize(async (object) => {
     // Google Vision API
     const visionResults = await analyzeWithGoogleVision(object);
     
     // Fallback to OpenAI if needed
     if (visionResults.confidence < 0.7) {
       const openAIResults = await callOpenAIVisionAPI(object);
       await storeAnalysisResults(openAIResults);
     }
     
     // Moderation check
     await runContentModeration(object);
   });
```

### B. Key Services
1. **Google Cloud**  
   - Landmark Detection API
   - Places API (location details)
   - Cloud Vision (image analysis)

2. **OpenAI**  
   - GPT-4 Vision (fallback analysis)
   - Metadata extraction
   - Content summarization

3. **Firebase ML**  
   - On-device model serving
   - Custom model deployment

## 4. Updated MVP Development Plan

### Week 1: Core App
1. Firebase integration
   - Anonymous auth flow
   - Firestore data modeling
   - Cloud Storage setup

2. Camera system
   - Google Vision API integration
   - Basic confidence display

3. Content pipeline
   - Firebase video streaming
   - Simple moderation rules
   - Static map generation workflow

### Week 2: AI Features
1. MLLM fallback system
   - OpenAI integration
   - Confidence comparison UI

2. Automated moderation
   - NSFW detection
   - Quality scoring

3. Metadata extraction
   - Business hour parsing
   - Price range detection

## 5. Error Handling Strategy

### Critical Paths
1. Landmark Detection Fallback:
   ```swift
   func handleDetectionError(_ error: Error) {
     if isVisionAPIError(error) {
       initiateMLLMFallback()
       logErrorToCrashlytics(error)
     }
   }
   ```

2. Content Upload Recovery:
   - Resumeable uploads
   - Local draft saving
   - Moderation retry queue

### Monitoring
- Firebase Crashlytics integration
- LangFuse for AI pipeline observability
- Cloud Function logging

================
File: _docs/archive/technical-requirements.md
================
# Technical Requirements

## 2.1 iOS App

### Platform
- iOS 15+ (Swift 5.x)

### Key Libraries
- Firebase iOS SDK (Auth, Firestore, Storage, etc.)
- AVFoundation (for video capture/playback)
- SwiftUI or UIKit (developer preference—no strict requirement)

### Core Features

#### Camera Landmark Detection
- Real-time or snapshot-based detection using Google Landmark API
- Fallback: none for Week 1

#### Content Feed
- Display list/grid of videos from Firestore
- Stream from Firebase Storage

#### Location Details
- Show static map image (server-generated or Google Static Maps)
- Deep link to Apple Maps for directions

#### User Accounts
- Anonymous Auth → Social/Email upgrade
- Store user data in Firestore under `users/{userId}`

#### Video Recording & Upload
- Capture short-form videos with AVFoundation
- Upload to Firebase Storage -> Cloud Function triggers AI processing

### Data Models (iOS Layer)

```swift
struct UserProfile {
    let uid: String
    let isAnonymous: Bool
    let savedPlaces: [String] // array of place IDs
}

struct Place {
    let placeId: String
    let name: String
    let coordinates: (lat: Double, lng: Double)
    let isLandmark: Bool
    let unlocked: Bool
    // Additional fields as needed
}

struct VideoContent {
    let videoId: String
    let storagePath: String
    let placeId: String
    let uploaderId: String
    // Basic metadata: title, category, etc.
}
```

## 2.2 Firebase Backend

### Services
- Authentication (anonymous, upgrade to full account)
- Firestore for storing user data, place data, video metadata
- Cloud Storage for uploaded videos
- Cloud Functions for AI tasks (Week 2)

### Firestore Structure

```yaml
Copy
users/
  {userId}/
    savedPlaces: [ {placeId}, ... ]
places/
  {placeId}/
    name: "Golden Gate Bridge"
    coordinates: ...
    ...
videos/
  {videoId}/
    placeId: ...
    uploaderId: ...
    moderationStatus: "approved" | "flagged"
```


### Cloud Functions

- `onFinalize` for video uploads → triggers AI pipeline (categorization, moderation, etc.) in Week 2
- Potential HTTP endpoints for fallback detection or additional functionality

## 2.3 AI Integrations (Week 2)

- **Google Landmark API**: Primary detection
- **Fallback MLLM**: If Landmark API fails or confidence < threshold
- **Content Moderation**: Basic NSFW / vulgar language detection
- **Metadata Extraction**: Business hours, price range, etc.

================
File: _docs/futures/content-gen/content-generation-prd.md
================
# Content Generation System PRD

## Overview
We need a system to generate video content for Austin neighborhoods, with landmarks serving as "unlock points" in the consumer app. Each landmark unlocks access to a collection of local content videos about nearby restaurants, shops, and points of interest within walking distance.

## Success Metrics

- Generate content for 3 Austin neighborhoods (defined by central landmarks)
- For each neighborhood area:
  * 3-5 restaurant/bar videos
  * 3-5 shopping/retail videos
  * 3-5 cultural/historical videos
  * 1 landmark-specific videos
- Each video should be backed by credible local sources
- Processing time under 5 minutes per individual video

## Content Sources

We'll pull from established local voices and publications:

- Austin Chronicle neighborhood guides
- Eater Austin coverage
- Local bloggers and critics
- Historical archives for landmark content

## Processing Pipeline

### 1. Area Data Collection
A Bun script will take a landmark as an entry point and:

- Define the walkable radius/neighborhood bounds
- Identify key venues and points of interest
- Scrape relevant content for each location
- Store structured data in SQLite
- Collect public images for each venue

### 2. Content Generation

For each venue/point of interest:

- Generate focused video script
- Identify required visuals
- Create venue-specific talking points
- Package with source attribution

### 3. Video Production

Transform each content package into:

- 30-60 second focused video
- Clear narrative structure
- Location-specific visuals
- Professional voiceover

## Technical Requirements

### Storage

- Local: SQLite for processing and relationships
- Cloud: Firebase Storage for final videos

### APIs

- Perplexity API for research/fact gathering
- Firebase for asset storage
- Video generation service (TBD)

### Development

Simple Bun-served interface for:

- Managing neighborhood/venue relationships
- Content review and editing
- Process monitoring
- Asset preview

## Test Area: South Congress

Starting with South Congress Bridge as unlock point:

- Map nearby venues within walking distance
- Generate initial venue set
- Create first content collection
- Test neighborhood unlock flow

## Out of Scope

- Complex UI/UX
- Deployment infrastructure
- Multi-language support
- Advanced video effects
- Real-time updates
- User authentication

================
File: _docs/futures/content-gen/content-genreation-technical-overview.md
================
## 1. System Overview

### A. Development Environment

- Runtime: Bun for all local development and processing
- Storage:
  - Local: SQLite via Bun SQLite API
  - Cloud: Firebase Storage for assets, Firebase Realtime DB for production data

- APIs:
  - Perplexity API for content research/generation
  - Firebase APIs for cloud integration
  - Image APIs (TBD) for public image collection

### B. Core Processing Agents

1. Data Collection Agent

```typescript
interface Scraper {
  urls: string[];
  placeId: string;
  async scrape(): Promise<{
    placeData: PlaceData;
    recommendations: Recommendation[];
    images: ImageMetadata[];
  }>;
}

interface PlaceData {
  id: string;
  name: string;
  description: string;
  location: GeoPoint;
  primaryCategories: string[];
  lastUpdated: Date;
}

interface Recommendation {
  placeId: string;
  sourceUrl: string;
  content: string;
  sentiment: number;
  extractedAt: Date;
}
```

2. Content Summarization Agent

```typescript
interface ContentSummarizer {
  placeId: string;
  async generateSummary(): Promise<{
    summary: string;
    keyPoints: string[];
    localTips: string[];
    verifiedFacts: string[];
  }>;
}
```

3. Script Generation Agent

```typescript
interface ScriptGenerator {
  placeId: string;
  async generateScript(): Promise<{
    sections: ScriptSection[];
    requiredVisuals: VisualPrompt[];
    audioNotes: AudioDirection[];
  }>;
}
```

4. Video Production Agent

```typescript
interface VideoProducer {
  script: Script;
  assets: AssetCollection;
  async produce(): Promise<{
    videoUrl: string;
    segments: VideoSegment[];
    metadata: VideoMetadata;
  }>;
}
```

### C. Processing Pipeline

1. Data Collection Phase
   - Scrape configured URLs
   - Extract relevant content
   - Store in local SQLite
   - Download & cache images
   - Quality validation checks

2. Content Processing Phase
   - Generate place summaries
   - Cross-reference facts
   - Create content outline
   - Quality validation loop

3. Production Phase
   - Script generation
   - Asset preparation
   - Video generation
   - Final quality check

### D. Local Development UI

- Simple Bun-served web interface
- Basic CRUD operations
- Pipeline status monitoring
- Quality check interfaces
- Asset preview/management

## 2. Data Schema

```typescript
// Local SQLite Schema
interface Schema {
  places: {
    id: string;
    name: string;
    description: string;
    location: string; // JSON
    created_at: Date;
    updated_at: Date;
  };
  
  recommendations: {
    id: string;
    place_id: string;
    source_url: string;
    content: string;
    extracted_at: Date;
  };
  
  assets: {
    id: string;
    place_id: string;
    type: 'image' | 'video';
    url: string;
    metadata: string; // JSON
    created_at: Date;
  };
  
  scripts: {
    id: string;
    place_id: string;
    content: string; // JSON
    version: number;
    created_at: Date;
  };
}
```

## 3. Implementation Priorities

1. Core Infrastructure
   - Bun project setup
   - SQLite integration
   - Basic Firebase config

2. Data Collection
   - URL scraping system
   - Perplexity API integration
   - Image collection pipeline

3. Content Processing
   - Summary generation
   - Fact verification
   - Script generation

4. Video Production
   - Asset management
   - Video generation integration
   - Quality control system

5. Development UI
   - Basic status dashboard
   - Content preview/edit
   - Pipeline controls

================
File: _docs/user-stories/1-landmark-detection.md
================
# Landmark Detection

**As a user**, I want to point my camera at a landmark to unlock neighborhood content.

## Acceptance Criteria

- Camera opens on launch
- Landmark detection works
- Visual feedback on detection
- Unlocks neighborhood content

## Technical Dependencies

- Camera permissions
- Google Landmark API
- Basic local storage for neighborhood visibility

================
File: _docs/user-stories/10-metadata-extraction.md
================
# Metadata Extraction

**As a creator**, I want key details automatically pulled from my video.

## Acceptance Criteria

- Extract business hours
- Detect price range
- Show extracted info before publishing
- Allow corrections

## Technical Dependencies

- Entity extraction
- Structured data parsing

## AI Integration Notes

- Process during upload
- LangFuse integration for extraction quality tracking

================
File: _docs/user-stories/2-content-browsing.md
================
# Content Browsing

**As a user**, I want to browse video content in unlocked neighborhoods.

## Acceptance Criteria

- Video feed for unlocked areas
- Basic video playback
- Show location name > location feed view
- Handle failed loads

## Technical Dependencies

- Video player

================
File: _docs/user-stories/3-location-details.md
================
# Location Details

**As a user**, I want to view a location on a map and get directions.

## Acceptance Criteria

- Static map with location in reference to unlocked landmark
- Maps app deep link
- Basic location info from google places api

## Technical Dependencies

- Static map generation
- Deep linking
- places api

================
File: _docs/user-stories/4-user-accounts.md
================
# User Accounts

**As a user**, I want to create an account to save places and contribute content.

## Acceptance Criteria

- Anonymous -> registered flow
- FB/Social signup
- Handle auth errors
- Persist anon data after signup

## Technical Dependencies

- Firebase Auth
- Local data migration
- Error handling

================
File: _docs/user-stories/5-save-places.md
================
# Save Places

**As a user**, I want to save places to my map.

## Acceptance Criteria

- Save/unsave toggle
- View saved places
- Persist saves

## Technical Dependencies

- Firebase storage
- Basic state management

================
File: _docs/user-stories/6-video-reviews.md
================
# Video Reviews

**As a user**, I want to record video reviews to unlock areas.

## Acceptance Criteria

- Record video in app
- Handle recording + uploading errors
- Associate recording with location with google places api
- Update 'unlocked' areas


## Technical Dependencies

- Camera recording
- places api
- firebase storage

================
File: _docs/user-stories/7-auto-categorization.md
================
# Auto-Categorization

**As a creator**, I want my video automatically tagged during upload.

## Acceptance Criteria

- Extract topics from video
- Apply basic categories (food, shopping, etc.)
- Show tags before publishing
- Allow tag editing

## Technical Dependencies

- Speech-to-text processing
- Topic extraction
- Category classification

## AI Integration Notes

- Process videos during upload
- LangFuse integration for categorization accuracy tracking

================
File: _docs/user-stories/8-upload-moderation.md
================
# Upload Moderation

**As a creator**, I want immediate feedback if my video violates guidelines.

## Acceptance Criteria

- Analyze video during upload
- Block upload if violations found
- Show specific violation feedback
- Allow retrying with new video

## Technical Dependencies

- Real-time frame analysis
- Audio content checking
- Immediate feedback loop

## AI Integration Notes
- Process videos during upload
- Clear feedback on AI results
- LangFuse integration for moderation effectiveness tracking

================
File: _docs/user-stories/9-non-landmark-detection.md
================
# Non-Landmark Detection

**As a user**, I want to identify places even when they're not official landmarks.

## Acceptance Criteria

- Try Google Landmark API first
- Use MLLM fallback if no match
- Show confidence level
- Allow confirming location

## Technical Dependencies

- Primary landmark detection
- MLLM visual analysis fallback
- Basic confidence scoring

## AI Integration Notes

- Clear confidence indicators
- LangFuse integration for recognition rate tracking

================
File: _docs/user-stories/index.md
================
# MVP User Stories Overview

## First Checkpoint (Feb 5)

- [Landmark Detection](./landmark-detection.md)
- [Content Browsing](./content-browsing.md)
- [Location Details](./location-details.md)

## Full Release (Feb 7)

- [User Accounts](./user-accounts.md)
- [Save Places](./save-places.md)
- [Video Reviews](./video-reviews.md)

## AI Features (Week 2)

- [Auto-Categorization](./auto-categorization.md)
- [Upload Moderation](./upload-moderation.md)
- [Metadata Extraction](./metadata-extraction.md)
- [Non-Landmark Detection](./non-landmark-detection.md)

================
File: _docs/improve-camera.md
================
# Refactoring and Improved Detection Handling Plan

This document outlines a step-by-step plan to refactor the current landmark detection codebase and improve detection handling. You will end up with a modular codebase where camera frames are pre-processed using on-device analysis (e.g., Vision APIs) to only send stable and unique frames for network processing. This guide is thorough enough for a junior developer to follow and begin implementation.

---

## Table of Contents

1. [Overview](#overview)
2. [Goals](#goals)
3. [Directory Structure and Module Breakdown](#directory-structure-and-module-breakdown)
4. [Step-by-Step Refactoring Plan](#step-by-step-refactoring-plan)
5. [Improving Detection Handling](#improving-detection-handling)
6. [Integration and Testing](#integration-and-testing)
7. [Additional Tips](#additional-tips)

---

## Overview

The current implementation involves a monolithic landmark detection that sends a network request every second. Our objective is twofold:

1. **Refactor the code** to separate concerns (models, networking, view model, and UI) so it’s easier to maintain and extend.
2. **Improve detection handling** by using on-device image processing (e.g., via Vision APIs) to determine when to send a network request. This will reduce unnecessary requests while ensuring a smooth user experience—users simply hold up the camera, and the app intelligently scans and detects landmarks.

---

## Goals

- **Modularization:**  
  Separate domain models, view models, networking logic, image processing, and UI components into distinct files and directories.

- **Task Management & Cancellation:**  
  Introduce explicit task handles in the view model so that in-flight network requests can be cancelled when a new frame qualifies.

- **On-Device Preprocessing:**  
  Use Vision APIs or similar techniques to detect motion, focus, and frame uniqueness. Only send frames that are stable and different from previous ones.

- **Smooth User Experience:**  
  Ensure the user can hold up the camera and have the landmark detected without manual intervention, with visual cues to indicate processing.

---

## Directory Structure and Module Breakdown

Create a directory structure that separates the responsibilities:

- **Models:**  
  Contains domain models and data structures.  
  - `/Models/LandmarkInfo.swift`  
  - `/Models/Neighborhood.swift`  
  - `/Models/GeoBounds.swift`

- **ViewModels:**  
  Contains the logic for handling state and coordinating tasks.  
  - `/ViewModels/LandmarkDetectionViewModel.swift`

- **Services:**  
  Contains networking and image processing logic.  
  - `/Services/DetectionService.swift` (handles Firebase calls)  
  - `/Services/ImageProcessingManager.swift` (handles Vision API integration)

- **Views:**  
  Contains all SwiftUI views and UI components.  
  - `/Views/LandmarkDetectionView.swift`  
  - `/Views/CameraView.swift`  
  - `/Views/ScanningTransitionView.swift`  
  - `/Views/ScanningAnimation.swift`

---

## Step-by-Step Refactoring Plan

### 1. Separate Domain Models

Move your data structures into the `/Models` directory. For example, create a file called `LandmarkInfo.swift`:

<code>
struct LandmarkInfo: Identifiable {
    let id = UUID()
    let name: String
    let description: String?
    let detailedDescription: String?
    let websiteUrl: String?
    let imageUrl: String?
    let latitude: Double?
    let longitude: Double?
    let neighborhood: Neighborhood?

    // Initialization logic as required
}
</code>

Similarly, place `Neighborhood` and any other related models into their own files.

### 2. Isolate the View Model

Extract the logic for handling landmark detection and task management into `/ViewModels/LandmarkDetectionViewModel.swift`. Explicitly manage cancellation tokens, like so:

<code>
class LandmarkDetectionViewModel: ObservableObject {
    @Published var selectedImage: UIImage?
    @Published var detectionResult: String = ""
    @Published var detectedLandmark: LandmarkInfo?
    @Published var unlockStatus: String = ""
    @Published var isLoading = false

    private var detectionTask: Task<Void, Never>? = nil

    // Inject dependencies (e.g., detectionService, imageProcessingManager)
    private let detectionService = DetectionService.shared
    private let imageProcessingManager = ImageProcessingManager.shared

    // Start detection, cancelling any existing task
    func startDetection(for image: UIImage) {
        detectionTask?.cancel()
        detectionTask = Task {
            await detectLandmark(for: image)
        }
    }

    // Cancellation method
    func cancelDetection() {
        detectionTask?.cancel()
        detectionTask = nil
    }

    func detectLandmark(for image: UIImage) async {
        await MainActor.run {
            isLoading = true
            detectionResult = ""
            detectedLandmark = nil
        }

        // Processing logic goes here
        // Use detectionService to call Firebase detection,
        // and check periodically for Task.isCancelled to exit early
        // ...
        
        await MainActor.run {
            isLoading = false
        }
    }
}
</code>

### 3. Create the Detection Service

Encapsulate all Firebase networking calls in `/Services/DetectionService.swift`. This file acts as the single point for making and cancelling network requests:

<code>
class DetectionService {
    static let shared = DetectionService()

    private lazy var functions = Functions.functions()

    // Function to call Firebase cloud function for detection
    func annotateImage(with requestData: [String: Any]) async throws -> [String: Any]? {
        let result = try await functions.httpsCallable("annotateImage").call(requestData)
        return result.data as? [String: Any]
    }
}
</code>

### 4. Implement the Image Processing Manager

Place logic for image analysis in `/Services/ImageProcessingManager.swift`. This manager uses Vision APIs to decide if a frame is “stable” or unique:

<code>
class ImageProcessingManager {
    static let shared = ImageProcessingManager()

    // Example function that compares current frame with previous one
    func frameIsStable(currentImage: UIImage, previousImage: UIImage?) -> Bool {
        // Implement Vision analysis, focus detection, and frame similarity.
        // Return true if the frame is steady and distinct.
        return true // Placeholder logic.
    }
}
</code>

### 5. Update UI Components

Split the UI code into separate files under `/Views`. For example, `LandmarkDetectionView.swift` serves as the container view:

<code>
struct LandmarkDetectionView: View {
    @StateObject private var viewModel = LandmarkDetectionViewModel()
    @State private var isCameraMode = true

    var body: some View {
        NavigationView {
            // Contains your CameraView, scanning animations, etc.
            if isCameraMode {
                CameraView(onFrameCaptured: { image in
                    // Use the image processing manager to decide if this frame should be processed.
                    if viewModel.imageProcessingManager.frameIsStable(currentImage: image, previousImage: nil) {
                        viewModel.startDetection(for: image)
                    }
                })
            } else {
                // Gallery or other view mode
            }
        }
        .onDisappear {
            viewModel.cancelDetection()
        }
    }
}
</code>

---

## Improving Detection Handling

### 1. Integrate On-Device Preprocessing

- **Vision API Integration:**  
  Use Vision APIs to process a frame. Check for:
  - **Motion:** Are consecutive frames showing too much change?
  - **Focus:** Is the image in clear focus?
  - **Uniqueness:** Compare a frame’s histogram or fingerprint with the previous frame.

- **Example Pseudocode:**  
  (This code is only a guideline and must be adapted to your app's needs.)

<code>
func analyzeFrame(image: UIImage) -> Bool {
    // 1. Run Vision request to check for focus and quality.
    // 2. Compare against a saved version of the last processed image.
    // 3. Return true only if the frame is stable and unique.
    return true
}
</code>

### 2. Debounce and Throttle Network Requests

- **Debounce Logic:**  
  Implement a short delay mechanism after a detection is triggered so that you don’t fire off multiple network requests rapidly.  
  For example, wait 0.5 to 1 second before processing the next valid frame.

- **Task Cancellation:**  
  Ensure that any in-flight detection tasks are cancelled if a new valid frame is captured or if the view disappears.

### 3. Pipeline Overview

1. **Frame Capture:**  
   The `CameraView` continuously streams frames.
2. **Local Analysis:**  
   The `ImageProcessingManager` evaluates focus, motion, and uniqueness.
3. **Trigger Network Request:**  
   If the current frame is stable, the view model calls `DetectionService` to handle network detection.
4. **Cancellation:**  
   Use explicit task handles in the view model to cancel past requests if a new valid frame qualifies.

---

## Integration and Testing

- **Step-wise Integration:**  
  Begin by separating the modules as described. Test each part independently:
  - Ensure your models load correctly.
  - Test the detection service with dummy requests.
  - Validate that the image processing manager correctly identifies stable frames.
  - Integrate these parts in the view model and then complete the UI integration.
  
- **UI Feedback:**  
  Add visual cues (e.g., a focus reticle or scanning animation) to indicate when a stable frame is detected and submitted.

- **Debugging:**  
  Log key events such as:
  - When a frame is rejected (due to instability).
  - When a frame qualifies for submission.
  - When network tasks are cancelled.
  
  This will help in tuning thresholds for focus, motion, and frame uniqueness.

---

## Additional Tips

- **Dependency Injection:**  
  Where possible, inject dependencies (like service instances) into the view model. This enables easier testing and future swapping of implementations.

- **Comment Your Code:**  
  As you refactor, add clear comments explaining the purpose of each module and function. This is invaluable for future maintainers or junior developers.

- **Iterate in Small Steps:**  
  Commit and test each module individually. Start with a minimal working refactor before integrating Vision-based detection.

- **Keep Configuration Simple:**  
  Early on, define constant thresholds for frame stability. These can later be exposed as configurable parameters or refined through analytics.

- **User Experience Focus:**  
  Even though this is a prototype, design with the user in mind. A responsive, fluid experience will make iterative testing easier.

---

By following this plan, you will have refactored code that is cleaner, modular, and ready for the integration of advanced image processing logic. This will not only help in reducing unnecessary network calls but also ensure that the overall user experience remains seamless as you iterate on the prototype.

================
File: _docs/navplan.md
================
# Updated Navigation Implementation Plan

This document outlines the detailed plan to implement dual-mode navigation for our app—one with a vertically scrolling feed for broad content exploration (with TikTok-like snapping, preloading, and smart audio transitions) and a horizontally swipeable Place Details view for exploring reels specific to a given place. In addition, the plan covers enhanced navigation for switching neighborhoods and categories.

---

## 1. Overview

The goal is to deliver a seamless, modern user experience by supporting two distinct interaction models:

- **Vertical Feed (Broad Exploration):**  
  Users scroll vertically through a list of reels. Videos should start preloading and begin playback as soon as they are in (or near) the viewport. As the user scrolls, snapping behavior ensures that a reel "locks" into place, and audio mixing immediately mutes or reduces the outgoing video's audio even if the snap isn't complete.

- **Place Details View (In-Depth Exploration):**  
  When a reel's pill button (which displays the place name) is tapped, the app navigates to a Place Details view. This view features a fixed header displaying the place information (name, address, etc.) and a horizontally swipeable carousel underneath to navigate between reels about that place.

- **Neighborhood & Category Navigation:**  
  The top section of the content feed will include two horizontally scrollable selectors for neighborhoods and categories. These selectors update the feed when changed and need to do so in a smooth, non-jarring manner.

---

## 2. Overall Architecture and State Management

- **Navigation:**  
  - Wrap `MainTabView` with a `NavigationStack` to enable deep navigation
  - Define navigation destination enum:
    ```swift
    enum NavigationDestination: Hashable {
        case placeDetail(placeId: String, initialContentId: String)
    }
    ```
  - Enhance `AppState` to include navigation path management

- **State Management:**  
  - Extend existing `ContentFeedViewModel` rather than creating new ones:
    - Add video preloading coordination
    - Add scroll position and snap state management
    - Add audio transition management
  - Create a new `PlaceDetailViewModel` for place-specific state

- **Video Player Management:**
  - Build upon existing `AVQueuePlayer` + `AVPlayerLooper` implementation
  - Add preloading manager to handle multiple `AVPlayer` instances:
    - Maintain pool of 3-4 preloaded players maximum
    - Implement cleanup strategy for unused players
  - Coordinate audio transitions between players during scroll

---

## 3. Vertical Feed Implementation

### Layout & Scrolling Behavior
- **Feed Construction:**  
  - Replace current horizontal `TabView` in `ContentFeedView` with `ScrollView`
  - Maintain existing `ContentItemView` structure but adapt for vertical layout
  - Add scroll position monitoring using `GeometryReader`
  
- **Snapping Mechanism:**  
  - Implement custom scroll view coordinator to handle snap behavior
  - Use `ScrollViewReader` for programmatic scrolling
  - Maintain smooth video playback during snap transitions

### Video Preloading and Audio Control
- **Enhanced ContentItemViewModel:**
  - Add preloading state management
  - Maintain existing looping behavior during playback
  - Add volume control for cross-fade support

- **Preloading Strategy:**
  - Preload maximum 2 videos ahead and 1 behind current position
  - Implement memory-aware cleanup of distant preloaded content
  - Maintain existing video cleanup pattern from `ContentItemViewModel`

---

## 4. Place Details View Implementation

### Layout
- **Header:**  
  - Create a fixed header at the top of the `PlaceDetailView` that displays the place's name, address, and other pertinent details.
  
- **Horizontal Reel Carousel:**  
  - Below the header, implement a horizontally swipeable carousel using a `TabView` with the `.page` style.
  - Each cell in this carousel will display content similarly to `ContentItemView`; however, it can optionally share state (or simply restart video playback) to ensure smooth transitions.

### Transition from the Feed
- **Navigation Trigger:**  
  - Update `ContentItemView` with an overlay "pill" button. This button should be wrapped in a `NavigationLink` (or trigger programmatic navigation via the `NavigationStack` path) that pushes the Place Details view.
  
- **Seamless Context Passing:**  
  - Pass along the necessary place data (or an identifier to fetch data) and, if possible, any relevant video playback context to ensure a smooth transition between the broad feed and detail view.

---

## 5. Neighborhood and Category Filtering

### Interaction Model
- **Selectors:**  
  - At the top of the vertical feed, implement two horizontal scroll selectors:
    - **Neighborhood Selector:** Displays available neighborhoods. Tapping a neighborhood updates the active selection in the view model.
    - **Category Selector:** Shows content categories (e.g., Restaurants, Events). Changes update the feed state accordingly.
  
- **Smooth Transitions:**  
  - Implement smooth animations on selection change.
  - Consider debouncing input if rapid selection could trigger heavy content reloads.
  - Ensure that changing either filter instantly updates the content area while showing a temporary loading indicator if needed.

### State Synchronization
- Enhance `ContentFeedViewModel` with functions that:
  - Handle neighborhood and category changes by refreshing the content feed smoothly.
  - Optionally preload adjacent content based on the new selection.
  - Keep the UI responsive by offloading heavy data fetching to background tasks controlled via async/await.

---

## 6. Integration & Detailed State Management

### Video Player Coordination
- **Player Pool Management:**
  ```swift
  class VideoPlayerPool {
      private var preloadedPlayers: [String: AVQueuePlayer] // keyed by content ID
      private let maxPreloadedPlayers = 4
      
      func preloadVideo(for contentId: String)
      func cleanupDistantPlayers()
  }
  ```

- **Audio Transition Handling:**
  - Implement volume ramping between players
  - Maintain existing mute state management
  - Add cross-fade duration configuration

### Memory Management
- **Resource Limits:**
  - Set maximum of 4 preloaded videos at any time
  - Implement aggressive cleanup of unused video resources
  - Add memory pressure handling

- **Performance Monitoring:**
  - Add video preload time tracking
  - Monitor memory usage during scroll operations
  - Implement adaptive preloading based on device capabilities

### NavigationStack Integration
- **Global Navigation Setup:**  
  - Wrap the main content views (`ContentFeedView`, `PlaceDetailView`, etc.) in a `NavigationStack` linked to a global navigation path (e.g., maintained in `AppState`).
  
- **Navigation Destinations:**  
  - Define explicit navigation destinations so that tapping on the pill button in any reel cleanly pushes the Place Detail view.

### Video Playback & Preloading Coordination
- **Centralized Control:**  
  - Consider a shared video player state in the view model (or even a dedicated controller) to help manage preloading, volume transitions, and playback continuity between cells.
  
- **Async Coordination:**  
  - Utilize async methods or Combine pipelines to handle asynchronous loading of video content, ensuring that preloading and audio adjustments trigger reliably based on scroll events and snapping detection.

---

## 7. Testing & Performance Optimization

- **Unit & UI Testing:**  
  - Test the snapping logic using simulated scroll events.
  - Validate that preloading and audio transitions occur as expected through unit tests on the view models.
  - Manually test transitions between neighborhoods/categories to monitor for jank.

- **Performance Profiling:**  
  - Check memory usage during heavy scrolling to ensure that the preloading of videos does not leak resources.
  - Profile the responsiveness of the vertical feed to determine if further optimizations (or a shift to a more complex UICollectionView wrapper) become necessary.

---

## Conclusion

This updated plan details a dual-mode navigation structure that leverages both a TikTok-inspired vertical feed and a horizontally swipeable details view. It incorporates smart preloading, proactive audio control, and smooth transitions for neighborhood and category changes—all managed by a robust state management solution under a modern `NavigationStack` framework.

This plan should provide a clear roadmap for implementation. The focus is on delivering a smooth, responsive, and modern UX for the demo, even if that necessitates more complex state management to keep everything in sync.

================
File: _docs/o3.xml
================
<Plan>
Modify VideoPlayerManager.swift so that prepareForDisplay (and preloadVideo) waits for the AVPlayerItem to be ready (i.e. status == .readyToPlay) before calling play. This ensures that the first video is fully ready before play is invoked.
</Plan>

<file path="sightline/Services/VideoPlayerManager.swift" action="rewrite">
  <change>
    <description>Wait for the player item to be ready before calling play()</description>
    <content>
===
import AVFoundation
import Combine
import SwiftUI
import FirebaseStorage
import AVKit
import Foundation

@MainActor
final class VideoPlayerManager: ObservableObject {
    @Published private(set) var currentPlayer: AVPlayer?
    @Published private(set) var isLoading = false
    @Published private(set) var error: Error?
    
    private var playerLooper: AVPlayerLooper?
    private var cancellables = Set<AnyCancellable>()
    private var preloadedPlayers: [String: AVQueuePlayer] = [:]
    
    private var preloadTasks: [String: Task<Void, Never>] = [:]
    private let preloadLimit = 2 // Number of videos to preload in each direction
    
    private var currentlyPlayingUrl: String?
    
    func prepareForDisplay(url: String) async {
        cleanup() // Clean up any existing player first
        isLoading = true
        error = nil
        
        do {
            let downloadUrl = try await getDownloadURL(for: url)
            let asset = AVURLAsset(url: downloadUrl)
            
            guard try await asset.load(.isPlayable) else {
                throw NSError(domain: "VideoPlayerManager", code: -1,
                              userInfo: [NSLocalizedDescriptionKey: "Video is not playable"])
            }
            
            let item = AVPlayerItem(asset: asset)
            let player = AVQueuePlayer(playerItem: item)
            playerLooper = AVPlayerLooper(player: player, templateItem: item)
            
            // Wait until the player item is ready before playing
            try await waitUntilPlayerItemReady(item)
            
            player.publisher(for: \.status)
                .sink { [weak self] status in
                    if status == .failed {
                        self?.error = player.error
                    }
                }
                .store(in: &cancellables)
            
            self.currentPlayer = player
            self.isLoading = false
            player.play()
        } catch {
            self.error = error
            self.isLoading = false
        }
    }
    
    // Helper function to wait until the AVPlayerItem is ready to play
    private func waitUntilPlayerItemReady(_ item: AVPlayerItem) async throws {
        while item.status != .readyToPlay {
            if item.status == .failed {
                throw item.error ?? NSError(domain: "VideoPlayerManager", code: -1,
                                             userInfo: [NSLocalizedDescriptionKey: "Failed to load video"])
            }
            try await Task.sleep(nanoseconds: 50_000_000) // 50 ms delay
        }
    }
    
    func preloadVideos(for urls: [String], at index: Int) {
        // Cancel any existing preload tasks that are no longer needed
        cleanupDistantPreloads(currentIndex: index)
        
        // Calculate preload range (excluding the current index)
        let start = max(0, index - preloadLimit)
        let end = min(urls.count - 1, index + preloadLimit)
        
        for i in start...end where i != index {
            let url = urls[i]
            if preloadedPlayers[url] == nil && preloadTasks[url] == nil {
                preloadTasks[url] = Task {
                    await preloadVideo(url)
                }
            }
        }
    }
    
    private func preloadVideo(_ url: String) async {
        print("🔄 Preloading video: \(url)")
        do {
            let downloadUrl = try await getDownloadURL(for: url)
            let asset = AVURLAsset(url: downloadUrl)
            
            if try await asset.load(.isPlayable) {
                let item = AVPlayerItem(asset: asset)
                let player = AVQueuePlayer(playerItem: item)
                // Wait until the item is ready before storing the preloaded player
                try await waitUntilPlayerItemReady(item)
                preloadedPlayers[url] = player
                print("✅ Successfully preloaded: \(url)")
            }
        } catch {
            print("❌ Error preloading video: \(error)")
        }
        preloadTasks[url] = nil
    }
    
    private func cleanupDistantPreloads(currentIndex: Int) {
        // Cancel preload tasks for distant videos
        // (Implementation can be added later if needed.)
    }
    
    func playerFor(url: String) -> AVPlayer? {
        if url == currentlyPlayingUrl {
            return currentPlayer
        }
        return preloadedPlayers[url]
    }
    
    /// New async activation method.
    func activatePlayerAsync(for url: String) async {
        // If this video is already active, skip reactivation.
        if currentlyPlayingUrl == url, currentPlayer != nil {
            print("🔄 Video \(url) already active. Skipping reactivation.")
            return
        }
        
        print("🎥 Activating player for URL: \(url)")
        if let player = preloadedPlayers[url] {
            print("✅ Found preloaded player")
            cleanup()
            currentPlayer = player
            currentlyPlayingUrl = url
            await player.seek(to: .zero)
            player.play()
        } else {
            print("⚠️ No preloaded player found, loading directly")
            await prepareForDisplay(url: url)
            currentlyPlayingUrl = url
        }
    }
    
    private func getDownloadURL(for gsUrl: String) async throws -> URL {
        let storageRef = Storage.storage().reference(forURL: gsUrl)
        return try await storageRef.downloadURL()
    }
    
    func cleanup() {
        currentPlayer?.pause()
        playerLooper = nil
        currentPlayer = nil
        currentlyPlayingUrl = nil
        error = nil
        isLoading = false
        cancellables.removeAll()
    }
}

extension VideoPlayerManager {
    nonisolated static func create() async -> VideoPlayerManager {
        await MainActor.run { VideoPlayerManager() }
    }
}
===
    </content>
  </change>
</file>

================
File: firebase/functions/.eslintrc.json
================
{
  "root": true,
  "env": {
    "es6": true,
    "node": true
  },
  "extends": [
    "eslint:recommended",
    "google"
  ],
  "rules": {
    "quotes": ["error", "double"]
  },
  "parserOptions": {
    "sourceType": "module",
    "ecmaVersion": 2020
  }
}

================
File: firebase/functions/.gitignore
================
node_modules/
*.local

================
File: firebase/functions/index.js
================
/**
 * Copyright 2023 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import * as functions from "firebase-functions/v1";
import {defineString} from "firebase-functions/params";
import vision from "@google-cloud/vision";
import admin from "firebase-admin";

// Initialize Firebase Admin (add this before any other code)
admin.initializeApp();

const API_KEY = defineString("GOOGLE_MAPS_API_KEY");

// Fetch Neighborhood Data
/**
 * Fetches information from the Knowledge Graph API for a given landmark ID.
 * @param {string} latitude -   The latitude of the landmark.
 * @param {string} longitude - The longitude of the landmark.
 * @return {Promise<Object>} The information from the Knowledge Graph API.
 */
async function fetchNeighborhoodData(latitude, longitude) {
  const url = `https://maps.googleapis.com/maps/api/geocode/json?latlng=${latitude},${longitude}&result_type=neighborhood&key=${API_KEY.value()}`;

  try {
    const response = await fetch(url);
    const data = await response.json();
    console.log(data);
    if (data.results && data.results.length > 0) {
      const neighborhood = data.results[0];
      return {
        place_id: neighborhood.place_id,
        name: neighborhood.address_components[0].long_name,
        bounds: neighborhood.geometry.bounds,
        formatted_address: neighborhood.formatted_address,
      };
    }
    return null;
  } catch (error) {
    console.error("Error fetching neighborhood data:", error);
    return null;
  }
}

// For more fine-grained control, you may add additional failure checks, ie:
//    || context.auth.token?.firebase?.email_verified === false
// Also see: https://firebase.google.com/docs/auth/admin/custom-claims
export const annotateImage = functions.https.onCall(async (data, context) => {
  if (!context?.auth) {
    throw new functions.https.HttpsError(
        "unauthenticated",
        "annotateImage must be called while authenticated.",
    );
  }

  const client = new vision.ImageAnnotatorClient();

  try {
    const [result] = await client.annotateImage(data);

    // If no landmarks found, return null
    if (!result.landmarkAnnotations?.length) {
      return {landmark: null};
    }

    // Get the first landmark and extract its MID
    const firstLandmark = result.landmarkAnnotations[0];
    const landmarkMid = firstLandmark.mid;
    // Sanitize the landmark MID for use as a
    // Firestore document ID (remove leading
    // slash and replace inner "/" with "_")
    const sanitizedMid = landmarkMid ?
      landmarkMid.startsWith("/") ?
        landmarkMid.slice(1).replace(/\//g, "_") :
        landmarkMid :
      null;
    console.log(
        "Detected landmark:",
        firstLandmark,
        "Using sanitized MID:",
        sanitizedMid,
    );

    const location = firstLandmark.locations[0].latLng;

    // Fetch Knowledge Graph data for just this landmark
    const neighborhoodData = await fetchNeighborhoodData(
        location.latitude,
        location.longitude,
    );

    console.log("Neighborhood Data:", neighborhoodData);

    // Get a Firestore reference
    const db = admin.firestore();

    // Update the central neighborhood document with
    // landmark info, including the unique MID
    if (neighborhoodData?.place_id) {
      await db
          .collection("neighborhoods")
          .doc(neighborhoodData.place_id)
          .set(
              {
                name: neighborhoodData.name,
                bounds: neighborhoodData.bounds,
                landmarks: admin.firestore.FieldValue.arrayUnion({
                  mid: sanitizedMid,
                  name: firstLandmark.description,
                  location: new admin.firestore.GeoPoint(
                      location.latitude,
                      location.longitude,
                  ),
                }),
              },
              {merge: true},
          );
    }

    // Update the user's unlocked_neighborhoods
    // document to reference the landmark MID
    if (
      context.auth &&
      context.auth.uid &&
      neighborhoodData?.place_id &&
      sanitizedMid
    ) {
      await db
          .collection("users")
          .doc(context.auth.uid)
          .collection("unlocked_neighborhoods")
          .doc(neighborhoodData.place_id)
          .set(
              {
                unlocked_at: admin.firestore.FieldValue.serverTimestamp(),
                unlocked_by_landmark: "Vision API",
                landmark_mid: sanitizedMid,
                landmark_location: new admin.firestore.GeoPoint(
                    location.latitude,
                    location.longitude,
                ),
              },
              {merge: true},
          );
    }

    // Save or update the detected landmark in its own collection
    if (sanitizedMid) {
      await db.collection("detectedLandmarks").doc(sanitizedMid).set(
          {
            name: firstLandmark.description,
            locations: firstLandmark.locations,
            score: firstLandmark.score,
            detected_at: admin.firestore.FieldValue.serverTimestamp(),
          },
          {merge: true},
      );
    }

    // Return a simplified response including the MID
    const landmark = {
      landmark: {
        name: firstLandmark.description,
        mid: sanitizedMid,
        score: firstLandmark.score,
        locations: firstLandmark.locations,
        neighborhood: neighborhoodData,
      },
    };
    console.log("Returning landmark response:", landmark);
    return landmark;
  } catch (err) {
    console.error("Error calling Vision API:", err);
    throw new functions.https.HttpsError("internal", err.message);
  }
});

================
File: firebase/functions/package.json
================
{
  "name": "functions",
  "description": "Cloud Functions for Firebase",
  "scripts": {
    "lint": "eslint . --fix",
    "serve": "firebase emulators:start --only functions",
    "shell": "firebase functions:shell",
    "start": "npm run shell",
    "deploy": "firebase deploy --only functions",
    "logs": "firebase functions:log"
  },
  "engines": {
    "node": "20"
  },
  "main": "index.js",
  "dependencies": {
    "@google-cloud/vision": "^4.3.2",
    "@googlemaps/google-maps-services-js": "^3.4.0",
    "firebase-admin": "^12.7.0",
    "firebase-functions": "^6.0.1",
    "geohash": "^0.0.1",
    "node-fetch": "^3.3.2"
  },
  "devDependencies": {
    "eslint": "^8.15.0",
    "eslint-config-google": "^0.14.0",
    "firebase-functions-test": "^3.1.0"
  },
  "private": true,
  "type": "module"
}

================
File: firebase/firebase.json
================
{
  "firestore": {
    "rules": "firestore.rules",
    "indexes": "firestore.indexes.json"
  },
  "functions": [
    {
      "source": "functions",
      "codebase": "default",
      "ignore": [
        "node_modules",
        ".git",
        "firebase-debug.log",
        "firebase-debug.*.log",
        "*.local"
      ],
      "predeploy": [
        "npm --prefix \"$RESOURCE_DIR\" run lint"
      ]
    }
  ],
  "storage": {
    "rules": "storage.rules"
  }
}

================
File: firebase/firestore.indexes.json
================
{
  "indexes": [],
  "fieldOverrides": []
}

================
File: firebase/firestore.rules
================
rules_version = '2';

service cloud.firestore {
  match /databases/{database}/documents {

    // This rule allows anyone with your Firestore database reference to view, edit,
    // and delete all data in your Firestore database. It is useful for getting
    // started, but it is configured to expire after 30 days because it
    // leaves your app open to attackers. At that time, all client
    // requests to your Firestore database will be denied.
    //
    // Make sure to write security rules for your app before that time, or else
    // all client requests to your Firestore database will be denied until you Update
    // your rules
    match /{document=**} {
      allow read, write: if request.time < timestamp.date(2025, 3, 6);
    }
  }
}

================
File: firebase/storage.rules
================
rules_version = '2';

// Craft rules based on data in your Firestore database
// allow write: if firestore.get(
//    /databases/(default)/documents/users/$(request.auth.uid)).data.isAdmin;
service firebase.storage {
  match /b/{bucket}/o {
    match /{allPaths=**} {
      allow read, write: if false;
    }
  }
}

================
File: sightline/sightline/Assets.xcassets/AccentColor.colorset/Contents.json
================
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/AppIcon.appiconset/Contents.json
================
{
  "images" : [
    {
      "filename" : "Icon-1024.png",
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "dark"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "tinted"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/discoverbg.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "discoverbg.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/Icon-1024.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "Icon-1024.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/ladybirdlake1.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "ladybirdlake1.jpeg",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/nocontent.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "nocontent.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/profile-bg.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "profile-bg.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/utcapitol1.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "utcapital1.jpeg",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/utcapitol2.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "utcapitol2.jpeg",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Models/Content.swift
================
import FirebaseFirestore

struct Content: Identifiable, Codable, Equatable {
    let id: String
    let placeIds: [String]      // References to one or more Places
    let eventIds: [String]?     // Optional references to one or more Events
    let neighborhoodId: String
    let authorId: String
    
    // Media
    var videoUrl: String
    let thumbnailUrl: String
    
    // Content details
    let caption: String
    let tags: [FilterCategory]  // Using the same FilterCategory for consistency
    
    // Metrics
    let likes: Int
    let views: Int
    
    // Timestamps
    let createdAt: Timestamp
    let updatedAt: Timestamp
    
    // Equatable implementation (ignoring timestamps and simple comparisons)
    static func == (lhs: Content, rhs: Content) -> Bool {
        lhs.id == rhs.id &&
        lhs.placeIds == rhs.placeIds &&
        lhs.eventIds == rhs.eventIds &&
        lhs.neighborhoodId == rhs.neighborhoodId &&
        lhs.authorId == rhs.authorId &&
        lhs.videoUrl == rhs.videoUrl &&
        lhs.thumbnailUrl == rhs.thumbnailUrl &&
        lhs.caption == rhs.caption &&
        lhs.tags == rhs.tags &&
        lhs.likes == rhs.likes &&
        lhs.views == rhs.views
    }
    
    init(
        id: String,
        placeIds: [String],
        eventIds: [String]? = nil,
        neighborhoodId: String,
        authorId: String,
        videoUrl: String,
        thumbnailUrl: String,
        caption: String,
        tags: [FilterCategory],
        likes: Int,
        views: Int,
        createdAt: Timestamp = Timestamp(),
        updatedAt: Timestamp = Timestamp()
    ) {
        self.id = id
        self.placeIds = placeIds
        self.eventIds = eventIds
        self.neighborhoodId = neighborhoodId
        self.authorId = authorId
        self.videoUrl = videoUrl
        self.thumbnailUrl = thumbnailUrl
        self.caption = caption
        self.tags = tags
        self.likes = likes
        self.views = views
        self.createdAt = createdAt
        self.updatedAt = updatedAt
    }
}

================
File: sightline/sightline/Models/Event.swift
================
import FirebaseFirestore

struct Event: Identifiable, Codable {
    let id: String
    let placeId: String                // The event is hosted at a specific Place
    let name: String
    let description: String?
    let startTime: Timestamp
    let endTime: Timestamp?
    let tags: [FilterCategory]         // Use the same tagging system as Place and Content
    let thumbnailUrl: String?
    let createdAt: Timestamp
    let updatedAt: Timestamp
    
    init(
        id: String,
        placeId: String,
        name: String,
        description: String? = nil,
        startTime: Timestamp,
        endTime: Timestamp? = nil,
        tags: [FilterCategory] = [],
        thumbnailUrl: String? = nil,
        createdAt: Timestamp = Timestamp(),
        updatedAt: Timestamp = Timestamp()
    ) {
        self.id = id
        self.placeId = placeId
        self.name = name
        self.description = description
        self.startTime = startTime
        self.endTime = endTime
        self.tags = tags
        self.thumbnailUrl = thumbnailUrl
        self.createdAt = createdAt
        self.updatedAt = updatedAt
    }
}

================
File: sightline/sightline/Models/FilterCategory.swift
================
enum FilterCategory: String, Codable, CaseIterable, Identifiable {
    case restaurant
    case drinks
    case events
    case music
    case art
    case outdoors
    case shopping
    case coffee
    
    var id: String { rawValue }
}

================
File: sightline/sightline/Models/Neighborhood.swift
================
import FirebaseFirestore  // For GeoPoint

struct Neighborhood: Codable, Identifiable, Equatable {
    @DocumentID var id: String?
    let name: String
    let description: String?
    let imageUrl: String?
    let bounds: GeoBounds
    let landmarks: [Landmark]?
    
    struct GeoBounds: Codable {
        struct Point: Codable {
            let lat: Double
            let lng: Double
        }
        let northeast: Point
        let southwest: Point
    }
    
    struct Landmark: Codable {
        let location: GeoPoint
        let mid: String
        let name: String
    }
    
    static func == (lhs: Neighborhood, rhs: Neighborhood) -> Bool {
        return lhs.id == rhs.id
    }
}

================
File: sightline/sightline/Models/Place.swift
================
import FirebaseFirestore

struct Place: Identifiable, Codable {
    let id: String
    let name: String
    let primaryCategory: FilterCategory           // e.g., "restaurant", "bar"
    let tags: [FilterCategory]                      // Controlled tags for searching and filtering
    
    // Other properties...
    let rating: Double
    let reviewCount: Int
    let coordinates: GeoPoint
    let neighborhoodId: String
    let address: String
    let description: String?                        // New property for place description
    let thumbnailUrl: String?
    let details: [String: String]
    let createdAt: Timestamp
    let updatedAt: Timestamp
    
    init(
        id: String,
        name: String,
        primaryCategory: FilterCategory,
        tags: [FilterCategory],
        rating: Double,
        reviewCount: Int,
        coordinates: GeoPoint,
        neighborhoodId: String,
        address: String,
        description: String? = nil,                // Default value nil
        thumbnailUrl: String?,
        details: [String: String],
        createdAt: Timestamp = Timestamp(),
        updatedAt: Timestamp = Timestamp()
    ) {
        self.id = id
        self.name = name
        self.primaryCategory = primaryCategory
        self.tags = tags
        self.rating = rating
        self.reviewCount = reviewCount
        self.coordinates = coordinates
        self.neighborhoodId = neighborhoodId
        self.address = address
        self.description = description
        self.thumbnailUrl = thumbnailUrl
        self.details = details
        self.createdAt = createdAt
        self.updatedAt = updatedAt
    }
}

================
File: sightline/sightline/Preview Content/Preview Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: sightline/sightline/Services/AuthService.swift
================
import FirebaseAuth

protocol AuthServiceProtocol {
    // Properties
    var currentUser: User? { get }
    var userId: String? { get }
    var isAuthenticated: Bool { get }
    
    // Methods
    func signInAnonymously() async throws
    func signOut() throws
}

class AuthService: AuthServiceProtocol {
    private let auth = Auth.auth()
    
    var currentUser: User? {
        auth.currentUser
    }
    
    var userId: String? {
        currentUser?.uid
    }
    
    var isAuthenticated: Bool {
        currentUser != nil
    }
    
    func signInAnonymously() async throws {
        // Only sign in if not already authenticated
        guard currentUser == nil else { return }
        
        do {
            let result = try await auth.signInAnonymously()
            print("Signed in anonymously with uid: \(result.user.uid)")
        } catch {
            print("Error signing in: \(error.localizedDescription)")
            throw error
        }
    }
    
    func signOut() throws {
        try auth.signOut()
    }
}

================
File: sightline/sightline/Services/FirestoreError.swift
================
enum FirestoreError: Error {
    case decodingError
    case documentNotFound
    case invalidData
}

================
File: sightline/sightline/Services/FirestoreService.swift
================
import FirebaseFirestore
import FirebaseStorage
import AVKit
import FirebaseAuth

protocol FirestoreServiceProtocol {
    // Neighborhoods
    func fetchUnlockedNeighborhoods(for userId: String) async throws -> [Neighborhood]
    
    // Test Data
//    func populateTestData() async throws
//    func deleteAllTestData() async throws
    
    // Content
    func fetchContentForPlace(placeId: String) async throws -> [Content]
    func fetchContentByCategory(category: FilterCategory, neighborhoodId: String?) async throws -> [Content]
    func saveDetectionResult(landmarkName: String) async throws
    
    // Places
    func fetchPlace(id: String) async throws -> Place
    func fetchPlacesInNeighborhood(neighborhoodId: String) async throws -> [Place]
    func addPlace(_ place: Place) async throws
    func fetchAvailableCategories(for neighborhoodId: String) async throws -> [FilterCategory]
    
    // New for saving places
    func savePlaceForUser(userId: String, placeId: String) async throws
    func fetchSavedPlaceIds(for userId: String) async throws -> [String]
}

class FirestoreService: FirestoreServiceProtocol {
  
    let db = Firestore.firestore()
    let storage = Storage.storage()
    
    // MARK: - Places
    func fetchPlacesInNeighborhood(neighborhoodId: String) async throws -> [Place] {
        let query = db.collection("places").whereField("neighborhoodId", isEqualTo: neighborhoodId)
        let snapshot = try await query.getDocuments()
            
        return try snapshot.documents.map { try $0.data(as: Place.self) }
    }
    
    func addPlace(_ place: Place) async throws {
        try db.collection("places")
            .document(place.id)
            .setData(from: place)
    }
    
    func fetchPlace(id: String) async throws -> Place {
        let docRef = db.collection("places").document(id)
        let document = try await docRef.getDocument()
        return try document.data(as: Place.self)
    }
    
    // MARK: - Content
    func fetchContentForPlace(placeId: String) async throws -> [Content] {
        let snapshot = try await db.collection("content")
            .whereField("placeId", isEqualTo: placeId)
            .order(by: "createdAt", descending: true)
            .getDocuments()
            
        return snapshot.documents.compactMap { document in
            try? document.data(as: Content.self)
        }
    }
    
    func fetchContentByCategory(category: FilterCategory, neighborhoodId: String?) async throws -> [Content] {
        print("🔍 Fetching content for category: \(category.rawValue), neighborhood: \(neighborhoodId ?? "all")")
        
        var query = db.collection("content")
            .whereField("tags", arrayContains: category.rawValue)
            .order(by: "createdAt", descending: true)
        
        if let neighborhoodId = neighborhoodId {
            query = query.whereField("neighborhoodId", isEqualTo: neighborhoodId)
        }
        
        let snapshot = try await query.getDocuments()
        
        let content = snapshot.documents.compactMap { document -> Content? in
            guard let content = try? document.data(as: Content.self) else {
                print("⚠️ Failed to decode content: \(document.documentID)")
                return nil
            }
            return content
        }
        
        print("✅ Found \(content.count) content items")
        return content
    }


    func saveDetectionResult(landmarkName: String) async throws {
        let landmarkData: [String: Any] = [
            "name": landmarkName,
            "detectedAt": FieldValue.serverTimestamp()
        ]
        
        try await db.collection("detectedLandmarks")
            .addDocument(data: landmarkData)
    }
    
    func fetchUnlockedNeighborhoods(for userId: String) async throws -> [Neighborhood] {
        print("🔍 Fetching unlocked neighborhoods for user: \(userId)")
        
        // Get the unlocked neighborhoods from the user's subcollection
        let unlockedSnapshot = try await db.collection("users")
            .document(userId)
            .collection("unlocked_neighborhoods")
            .getDocuments()
        
        // Use the document IDs as the neighborhood IDs
        let neighborhoodIds = unlockedSnapshot.documents.map { $0.documentID }
        
        guard !neighborhoodIds.isEmpty else {
            print("⚠️ No unlocked neighborhoods found for user")
            return []
        }
        
        // Then fetch the actual neighborhoods from the neighborhoods collection
        let neighborhoodSnapshot = try await db.collection("neighborhoods")
            .whereField(FieldPath.documentID(), in: neighborhoodIds)
            .getDocuments()
        
        let neighborhoods = neighborhoodSnapshot.documents.compactMap { document -> Neighborhood? in
            try? document.data(as: Neighborhood.self)
        }
        
        print("✅ Found \(neighborhoods.count) unlocked neighborhoods")
        return neighborhoods
    }
    
    // Helper function to decode GeoBounds
    private func decodeGeoBounds(from data: [String: Any]) throws -> Neighborhood.GeoBounds {
        guard let northeast = data["northeast"] as? [String: Any],
              let southwest = data["southwest"] as? [String: Any] else {
            throw DecodingError.dataCorrupted(.init(codingPath: [], debugDescription: "Missing bounds data"))
        }
        
        return Neighborhood.GeoBounds(
            northeast: .init(
                lat: northeast["lat"] as? Double ?? 0,
                lng: northeast["lng"] as? Double ?? 0
            ),
            southwest: .init(
                lat: southwest["lat"] as? Double ?? 0,
                lng: southwest["lng"] as? Double ?? 0
            )
        )
    }
    
    // Helper function to decode Landmarks
    private func decodeLandmarks(from data: [[String: Any]]) throws -> [Neighborhood.Landmark]? {
        return data.compactMap { landmarkData in
            guard let location = landmarkData["location"] as? GeoPoint,
                  let mid = landmarkData["mid"] as? String,
                  let name = landmarkData["name"] as? String else {
                return nil
            }
            
            return Neighborhood.Landmark(
                location: location,
                mid: mid,
                name: name
            )
        }
    }

    func fetchAvailableCategories(for neighborhoodId: String) async throws -> [FilterCategory] {
        print("🔍 Fetching available categories for neighborhood: \(neighborhoodId)")
        
        let snapshot = try await db.collection("content")
            .whereField("neighborhoodId", isEqualTo: neighborhoodId)
            .getDocuments()
        
        // Create a Set to store unique categories
        var categorySet = Set<String>()
        
        // Collect all unique categories from content
        for document in snapshot.documents {
            if let tags = document.data()["tags"] as? [String] {
                categorySet.formUnion(tags)
            }
        }
        
        // Convert strings to FilterCategory and filter out invalid ones
        let categories = categorySet.compactMap { tagString -> FilterCategory? in
            return FilterCategory(rawValue: tagString)
        }.sorted { $0.rawValue < $1.rawValue }
        
        print("✅ Found \(categories.count) available categories")
        return categories
    }
    
    // MARK: - User Places (new)
    
    /// Save a place under the user's saved_places subcollection
    func savePlaceForUser(userId: String, placeId: String) async throws {
        let docRef = db.collection("users")
            .document(userId)
            .collection("saved_places")
            .document(placeId)
        
        try await docRef.setData([
            "savedAt": FieldValue.serverTimestamp()
        ])
    }
    
    /// Fetch only the IDs of saved places; we can fetch full docs separately
    func fetchSavedPlaceIds(for userId: String) async throws -> [String] {
        let snapshot = try await db.collection("users")
            .document(userId)
            .collection("saved_places")
            .getDocuments()
        
        return snapshot.documents.map { $0.documentID }
    }

    func createAnnotationRequest(imageURL: String, originalFilename: String) async throws {
        let annotationRequest = [
            "imageURL": imageURL,
            "originalFilename": originalFilename,
            "status": "pending",
            "createdAt": Timestamp(),
            "updatedAt": Timestamp()
        ] as [String : Any]
        
        try await db.collection("annotationRequests").addDocument(data: annotationRequest)
    }
}

================
File: sightline/sightline/Services/FirestoreService+TestData.swift
================
//#if DEBUG
//import FirebaseFirestore
//import FirebaseAuth
//
//extension FirestoreService {
//  // MARK: - Test Data Population
//  func populateTestData() async throws {
//    // First create our places
//    let places = [
//      Place(
//        id: "caroline_restaurant",
//        name: "Caroline",
//        primaryCategory: .restaurant,
//        tags: [.restaurant, .drinks],
//        rating: 4.6,
//        reviewCount: 285,
//        coordinates: GeoPoint(latitude: 30.2651, longitude: -97.7426),
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        address: "621 Congress Ave, Austin, TX 78701",
//        thumbnailUrl: nil,
//        details: ["cuisine": "American", "priceRange": "$$$"]
//      ),
//      
//      Place(
//        id: "casino_el_camino",
//        name: "Casino El Camino",
//        primaryCategory: .drinks,
//        tags: [.drinks, .music],
//        rating: 4.7,
//        reviewCount: 312,
//        coordinates: GeoPoint(latitude: 30.2670, longitude: -97.7411),
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        address: "517 E 6th St, Austin, TX 78701",
//        thumbnailUrl: nil,
//        details: ["type": "dive bar", "priceRange": "$$"]
//      ),
//      Place(
//        id: "firehouse_lounge",
//        name: "Firehouse Lounge",
//        primaryCategory: .drinks,
//        tags: [.drinks, .music],
//        rating: 4.7,
//        reviewCount: 312,
//        coordinates: GeoPoint(latitude: 30.2670, longitude: -97.7411),
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        address: "605 Brazos St, Austin, TX 78701",
//        thumbnailUrl: nil,
//        details: ["type": "Cocktail Bar", "priceRange": "$$"]
//      ),
//      
//      Place(
//        id: "floppy_disk_repair",
//        name: "Floppy Disk Repair Co",
//        primaryCategory: .drinks,
//        tags: [.drinks],
//        rating: 4.8,
//        reviewCount: 156,
//        coordinates: GeoPoint(latitude: 30.2665, longitude: -97.7362),
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        address: "119 E 5th St, Austin, TX 78701",
//        thumbnailUrl: nil,
//        details: ["type": "Speakeasy", "priceRange": "$$$"]
//      ),
//      
//      Place(
//        id: "zilker_botanical",
//        name: "Zilker Botanical Garden",
//        primaryCategory: .outdoors,
//        tags: [.outdoors],
//        rating: 4.6,
//        reviewCount: 892,
//        coordinates: GeoPoint(latitude: 30.2670, longitude: -97.7687),
//        neighborhoodId: "ChIJQ8GHMSG1RIYRd7-_VfluNVg",
//        address: "2220 Barton Springs Rd, Austin, TX 78746",
//        thumbnailUrl: nil,
//        details: ["type": "Garden", "admission": "$8-12"]
//      ),
//      
//      Place(
//        id: "zilker_park",
//        name: "Zilker Metropolitan Park",
//        primaryCategory: .outdoors,
//        tags: [.outdoors],
//        rating: 4.8,
//        reviewCount: 1423,
//        coordinates: GeoPoint(latitude: 30.2669, longitude: -97.7728),
//        neighborhoodId: "ChIJQ8GHMSG1RIYRd7-_VfluNVg",
//        address: "2207 Lou Neff Rd, Austin, TX 78746",
//        thumbnailUrl: nil,
//        details: ["type": "Park", "size": "351 acres"]
//      )
//    ]
//    
//    // Add all places
//    for place in places {
//      try await addPlace(place)
//    }
//    
//    // Create content items matching videos to places
//    let contentItems = [
//      // Capitol District content
//     
//      Content(
//        id: "caroline_highlight",
//        placeIds: ["caroline_restaurant"],
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/caroline.mp4",
//        thumbnailUrl: "",
//        caption: "Weekend brunch vibes at Caroline 🍳",
//        tags: [.restaurant, .drinks],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//       Content(
//        id: "casino1",
//        placeIds: ["casino_el_camino"],
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/casino.mp4",
//        thumbnailUrl: "",
//        caption: "Weekend brunch vibes at Caroline 🍳",
//        tags: [.restaurant, .drinks],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//      
//      Content(
//        id: "firehouse_music",
//        placeIds: ["firehouse_lounge"],
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/firehouse-music.mp4",
//        thumbnailUrl: "",
//        caption: "Live music at Firehouse 🎷",
//        tags: [.drinks, .music],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//      Content(
//        id: "casino2",
//        placeIds: ["casino_el_camino"],
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/firehouse.mp4",
//        thumbnailUrl: "",
//        caption: "Anothe thing vibes �",
//        tags: [.drinks],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//      
//      Content(
//        id: "floppy_drinks",
//        placeIds: ["floppy_disk_repair"],
//        neighborhoodId: "ChIJRyZGIaC1RIYRC6MZpgR-iT4",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/floppy.mp4",
//        thumbnailUrl: "",
//        caption: "Secret speakeasy vibes 🍸",
//        tags: [.drinks],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//      
//      // Zilker content
//      Content(
//        id: "zilker_botanical",
//        placeIds: ["zilker_botanical"],
//        neighborhoodId: "ChIJQ8GHMSG1RIYRd7-_VfluNVg",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/zilker-botanical.mp4",
//        thumbnailUrl: "",
//        caption: "Spring blooms at Zilker Botanical Garden 🌸",
//        tags: [.outdoors],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      ),
//      
//      Content(
//        id: "zilker_park",
//        placeIds: ["zilker_park"],
//        neighborhoodId: "ChIJQ8GHMSG1RIYRd7-_VfluNVg",
//        authorId: "test_author",
//        videoUrl: "gs://sightline-app-gauntlet.firebasestorage.app/zilker.mp4",
//        thumbnailUrl: "",
//        caption: "Perfect day at Zilker Park ☀️",
//        tags: [.outdoors],
//        likes: Int.random(in: 50...200),
//        views: Int.random(in: 500...2000)
//      )
//    ]
//    
//    // Add all content
//    for content in contentItems {
//      try await addContent(content)
//    }
//  }
//  
//  func deleteAllTestData() async throws {
//    // Delete content
//    let contentSnapshot = try await db.collection("content").getDocuments()
//    for doc in contentSnapshot.documents {
//      try await doc.reference.delete()
//    }
//    
//    // Delete places
//    let placesSnapshot = try await db.collection("places").getDocuments()
//    for doc in placesSnapshot.documents {
//      try await doc.reference.delete()
//    }
//    
//    // Delete neighborhoods
//    let neighborhoodsSnapshot = try await db.collection("neighborhoods").getDocuments()
//    for doc in neighborhoodsSnapshot.documents {
//      try await doc.reference.delete()
//    }
//    
//    // Delete unlocked neighborhoods for all users
//    if let userId = Auth.auth().currentUser?.uid {
//      let unlockedSnapshot = try await db.collection("users")
//        .document(userId)
//        .collection("unlocked_neighborhoods")
//        .getDocuments()
//      for doc in unlockedSnapshot.documents {
//        try await doc.reference.delete()
//      }
//    }
//  }
//}
//#endif

================
File: sightline/sightline/Services/ServiceContainer.swift
================
import Foundation

// Container for all app services
class ServiceContainer {
    // Shared instance
    static let shared = ServiceContainer()
    
    // Services
    let auth: AuthServiceProtocol
    let firestore: FirestoreServiceProtocol
    
    // Private init for singleton
    private init() {
        self.auth = AuthService()
        self.firestore = FirestoreService()
    }
}

================
File: sightline/sightline/Services/VideoPlayerManager.swift
================
import AVFoundation
import Combine
import SwiftUI
import FirebaseStorage
import AVKit
import Foundation

@MainActor
final class VideoPlayerManager: ObservableObject {
    @Published private(set) var currentPlayer: AVPlayer?
    @Published private(set) var isLoading = false
    @Published private(set) var error: Error?
    
    private var playerLooper: AVPlayerLooper?
    private var cancellables = Set<AnyCancellable>()
    
    // Dictionary to store preloaded players by URL
    private var preloadedPlayers: [String: AVQueuePlayer] = [:]
    // Queue to track the order of preloaded videos for caching purposes
    private var preloadedVideosQueue: [String] = []
    // Maximum number of videos to cache during the session
    private let maxCacheSize = 10
    
    private var preloadTasks: [String: Task<Void, Never>] = [:]
    private let preloadLimit = 2 // Number of videos to preload in each direction
    
    private var currentlyPlayingUrl: String?
    
    func prepareForDisplay(url: String) async {
        await cleanup() // Clean up any existing player first
        isLoading = true
        error = nil
        
        do {
            let downloadUrl = try await getDownloadURL(for: url)
            let asset = AVURLAsset(url: downloadUrl)
            
            guard try await asset.load(.isPlayable) else {
                throw NSError(domain: "VideoPlayerManager", code: -1,
                              userInfo: [NSLocalizedDescriptionKey: "Video is not playable"])
            }
            
            let item = AVPlayerItem(asset: asset)
            let player = AVQueuePlayer(playerItem: item)
            playerLooper = AVPlayerLooper(player: player, templateItem: item)
            
            // Wait until the player item is ready before playing
            try await waitUntilPlayerItemReady(item)
            
            player.publisher(for: \.status)
                .sink { [weak self] status in
                    if status == .failed {
                        self?.error = player.error
                    }
                }
                .store(in: &cancellables)
            
            self.currentPlayer = player
            self.isLoading = false
            player.play()
        } catch {
            self.error = error
            self.isLoading = false
        }
    }
    
    // Helper function to wait until the AVPlayerItem is ready to play
    private func waitUntilPlayerItemReady(_ item: AVPlayerItem) async throws {
        while item.status != .readyToPlay {
            if item.status == .failed {
                throw item.error ?? NSError(domain: "VideoPlayerManager", code: -1,
                                             userInfo: [NSLocalizedDescriptionKey: "Failed to load video"])
            }
            try await Task.sleep(nanoseconds: 50_000_000) // 50 ms delay
        }
    }
    
    func preloadVideos(for urls: [String], at index: Int) {
        // Cancel any existing preload tasks that are no longer needed
        cleanupDistantPreloads(currentIndex: index)
        
        // Calculate preload range (excluding the current index)
        let start = max(0, index - preloadLimit)
        let end = min(urls.count - 1, index + preloadLimit)
        
        for i in start...end where i != index {
            let url = urls[i]
            if preloadedPlayers[url] == nil && preloadTasks[url] == nil {
                preloadTasks[url] = Task {
                    await preloadVideo(url)
                }
            }
        }
    }
    
    private func preloadVideo(_ url: String) async {
        print("🔄 Preloading video: \(url)")
        do {
            let downloadUrl = try await getDownloadURL(for: url)
            let asset = AVURLAsset(url: downloadUrl)
            
            if try await asset.load(.isPlayable) {
                let item = AVPlayerItem(asset: asset)
                let player = AVQueuePlayer(playerItem: item)
                // Wait until the item is ready before storing the preloaded player
                try await waitUntilPlayerItemReady(item)
                preloadedPlayers[url] = player
                
                // Add to the caching queue and enforce maximum cache size
                preloadedVideosQueue.append(url)
                if preloadedVideosQueue.count > maxCacheSize {
                    let oldestUrl = preloadedVideosQueue.removeFirst()
                    preloadedPlayers[oldestUrl]?.pause()
                    preloadedPlayers[oldestUrl] = nil
                    print("🗑 Purged oldest video: \(oldestUrl) from cache")
                }
                
                print("✅ Successfully preloaded: \(url)")
            }
        } catch {
            print("❌ Error preloading video: \(error)")
        }
        preloadTasks[url] = nil
    }
    
    private func cleanupDistantPreloads(currentIndex: Int) {
        // Cancel preload tasks for distant videos
        // (Implementation can be added later if needed.)
    }
    
    func playerFor(url: String) -> AVPlayer? {
        if url == currentlyPlayingUrl {
            return currentPlayer
        }
        return preloadedPlayers[url]
    }
    
    /// New async activation method.
    func activatePlayerAsync(for url: String) async {
        // If this video is already active, skip reactivation.
        if currentlyPlayingUrl == url, currentPlayer != nil {
            print("🔄 Video \(url) already active. Skipping reactivation.")
            return
        }
        
        print("🎥 Activating player for URL: \(url)")
        if let player = preloadedPlayers[url] {
            print("✅ Found preloaded player")
            await cleanup()
            currentPlayer = player
            currentlyPlayingUrl = url
            await player.seek(to: .zero)
            player.play()
        } else {
            print("⚠️ No preloaded player found, loading directly")
            await prepareForDisplay(url: url)
            currentlyPlayingUrl = url
        }
    }
    
    private func getDownloadURL(for gsUrl: String) async throws -> URL {
        let storageRef = Storage.storage().reference(forURL: gsUrl)
        return try await storageRef.downloadURL()
    }
    
    func cleanup() async {
        currentPlayer?.pause()
        playerLooper = nil
        currentPlayer = nil
        currentlyPlayingUrl = nil
        error = nil
        isLoading = false
        cancellables.removeAll()
    }
    
    /// Clears the entire video cache. Call this on app close to release all cached videos.
    func clearCache() {
        preloadedPlayers.forEach { (_, player) in
            player.pause()
        }
        preloadedPlayers.removeAll()
        preloadedVideosQueue.removeAll()
        preloadTasks.removeAll()
        print("Cleared video cache")
    }
}

extension VideoPlayerManager {
    nonisolated static func create() async -> VideoPlayerManager {
        await MainActor.run { VideoPlayerManager() }
    }
}

================
File: sightline/sightline/sightline.xcdatamodeld/sightline.xcdatamodel/contents
================
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<model type="com.apple.IDECoreDataModeler.DataModel" documentVersion="1.0" lastSavedToolsVersion="1" systemVersion="11A491" minimumToolsVersion="Automatic" sourceLanguage="Swift" usedWithCloudKit="false" userDefinedModelVersionIdentifier="">
    <entity name="Item" representedClassName="Item" syncable="YES" codeGenerationType="class">
        <attribute name="timestamp" optional="YES" attributeType="Date" usesScalarValueType="NO"/>
    </entity>
    <elements>
        <element name="Item" positionX="-63" positionY="-18" width="128" height="44"/>
    </elements>
</model>

================
File: sightline/sightline/sightline.xcdatamodeld/.xccurrentversion
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>_XCCurrentVersionName</key>
	<string>sightline.xcdatamodel</string>
</dict>
</plist>

================
File: sightline/sightline/State/AppState.swift
================
import SwiftUI

class AppState: ObservableObject {
    @Published var shouldSwitchToFeed = false
    @Published var shouldSwitchToDiscover = false
    @Published var lastUnlockedNeighborhoodId: String?
    @Published var navigationPath = NavigationPath()
    
    // New property to navigate directly to Profile tab
    @Published var shouldSwitchToProfile = false
    
    enum NavigationDestination: Hashable {
        case placeDetail(placeId: String, initialContentId: String)
    }
}

================
File: sightline/sightline/State/AppViewModel.swift
================
import SwiftUI

@MainActor
final class AppViewModel: ObservableObject {
    @Published private(set) var isPreloading = true
    private let services = ServiceContainer.shared
    
    func preloadAppData() async {
        guard let userId = services.auth.userId else { return }
        
        do {
            // Preload neighborhoods
            let neighborhoods = try await services.firestore.fetchUnlockedNeighborhoods(for: userId)
            
            // If we have neighborhoods, preload categories for the first one
            if let firstNeighborhood = neighborhoods.first {
                let categories = try await services.firestore.fetchAvailableCategories(
                    for: firstNeighborhood.id!
                )
                
                // Store preloaded data in UserDefaults for immediate access
                if let encodedNeighborhoods = try? JSONEncoder().encode(neighborhoods) {
                    UserDefaults.standard.set(encodedNeighborhoods, forKey: "preloadedNeighborhoods")
                }
                if let encodedCategories = try? JSONEncoder().encode(categories) {
                    UserDefaults.standard.set(encodedCategories, forKey: "preloadedCategories")
                }
            }
        } catch {
            print("Error preloading app data: \(error)")
        }
        
        isPreloading = false
    }
}

================
File: sightline/sightline/Views/Components/AdaptiveColorButton.swift
================
import SwiftUI
import UIKit

struct AdaptiveColorButton<Label: View>: View {
    let action: () -> Void
    let label: () -> Label
    let isSelected: Bool
    let expandHorizontally: Bool  // New parameter

    init(
        isSelected: Bool,
        expandHorizontally: Bool = false, // default false
        action: @escaping () -> Void,
        @ViewBuilder label: @escaping () -> Label
    ) {
        self.isSelected = isSelected
        self.expandHorizontally = expandHorizontally
        self.action = action
        self.label = label
    }
    
    var body: some View {
        Button(action: action) {
            ZStack {
                // Background layers for the button
                Color.white.opacity(isSelected ? 0.95 : 0.4)
                    .background(.ultraThickMaterial)
                    .frame(height: 36) // Slightly reduced height for more squared look
                    .cornerRadius(8)   // Much smaller corner radius
                    // Lighter shadow for squared look
                    .shadow(color: .black.opacity(0.2), radius: 4, x: 0, y: 2)
                    .overlay {
                        // Subtle gradient for depth
                        LinearGradient(
                            colors: [
                                .white.opacity(0.6),
                                .gray.opacity(0.1)
                            ],
                            startPoint: .topLeading,
                            endPoint: .bottomTrailing
                        )
                        .cornerRadius(8)
                    }
                    .overlay {
                        // Glassy border
                        RoundedRectangle(cornerRadius: 8)
                            .stroke(.white.opacity(0.5), lineWidth: 1)
                    }
                
                // Button label
                label()
                    .foregroundColor(.black)
                    .controlSize(.small)
                    .padding(.horizontal, 12)
                    .padding(.vertical, 8)
            }
            .fixedSize(horizontal: true, vertical: false)
            .frame(height: 36)
        }
        .scaleEffect(isSelected ? 0.98 : 1.0)
        .animation(.spring(response: 0.3, dampingFraction: 0.7), value: isSelected)
    }
}

// [The rest of the file remains unchanged below...]
private struct ColorPreferenceKey: PreferenceKey {
    static var defaultValue: CGRect = .zero
    
    static func reduce(value: inout CGRect, nextValue: () -> CGRect) {
        value = nextValue()
    }
}

extension UIImage {
    func cropToFrame(_ frame: CGRect) -> UIImage {
        guard let cgImage = self.cgImage else { return self }
        let scaledFrame = CGRect(
            x: frame.origin.x * scale,
            y: frame.origin.y * scale,
            width: frame.width * scale,
            height: frame.height * scale
        )
        guard let croppedCGImage = cgImage.cropping(to: scaledFrame) else { return self }
        return UIImage(cgImage: croppedCGImage)
    }
    
    func averageColor() -> UIColor {
        guard let inputImage = CIImage(image: self) else { return .white }
        let extentVector = CIVector(x: inputImage.extent.origin.x,
                                  y: inputImage.extent.origin.y,
                                  z: inputImage.extent.size.width,
                                  w: inputImage.extent.size.height)

        guard let filter = CIFilter(name: "CIAreaAverage",
                                  parameters: [kCIInputImageKey: inputImage,
                                             kCIInputExtentKey: extentVector]) else { return .white }
        guard let outputImage = filter.outputImage else { return .white }

        var bitmap = [UInt8](repeating: 0, count: 4)
        let context = CIContext(options: [.workingColorSpace: kCFNull as Any])
        context.render(outputImage,
                      toBitmap: &bitmap,
                      rowBytes: 4,
                      bounds: CGRect(x: 0, y: 0, width: 1, height: 1),
                      format: .RGBA8,
                      colorSpace: nil)

        return UIColor(red: CGFloat(bitmap[0]) / 255,
                      green: CGFloat(bitmap[1]) / 255,
                      blue: CGFloat(bitmap[2]) / 255,
                      alpha: CGFloat(bitmap[3]) / 255)
    }
}

extension UIColor {
    func getBrightness() -> CGFloat {
        var red: CGFloat = 0
        var green: CGFloat = 0
        var blue: CGFloat = 0
        var alpha: CGFloat = 0
        
        getRed(&red, green: &green, blue: &blue, alpha: &alpha)
        
        // Using perceived brightness formula
        return ((red * 299) + (green * 587) + (blue * 114)) / 1000
    }
}

#Preview {
    VStack(spacing: 20) {
        // Default state
        AdaptiveColorButton(isSelected: false) {
            
        } label: {
            Text("Default Button")
        }
        
        // Selected state
        AdaptiveColorButton(isSelected: true) {
            
        } label: {
            Text("Selected Button")
        }
        
        // Long text
        AdaptiveColorButton(isSelected: false) {
            
        } label: {
            Text("Button with Longer Text")
        }
        
        // With SF Symbol
        AdaptiveColorButton(isSelected: false) {
            
        } label: {
            HStack {
                Image(systemName: "star.fill")
                Text("Icon Button")
            }
        }
    }
    .padding()
    .frame(maxWidth: .infinity)  // <-- Add this to show alignment
    .background(Color.black) // Dark background to match app context
}

================
File: sightline/sightline/Views/Components/FloatingMenuButton.swift
================
import SwiftUI

// Helper modifier to conditionally apply modifiers.
extension View {
    @ViewBuilder func `if`<Content: View>(
        _ condition: Bool,
        transform: (Self) -> Content
    ) -> some View {
        if condition {
            transform(self)
        } else {
            self
        }
    }
}

struct FloatingMenuButton<Label: View>: View {
    let action: () -> Void
    let label: () -> Label
    let isSelected: Bool
    let expandHorizontally: Bool

    @State private var buttonFrame: CGRect = .zero

    init(
        action: @escaping () -> Void,
        isSelected: Bool = false,
        expandHorizontally: Bool = false,
        @ViewBuilder label: @escaping () -> Label
    ) {
        self.action = action
        self.isSelected = isSelected
        self.expandHorizontally = expandHorizontally
        self.label = label
    }

    var body: some View {
        AdaptiveColorButton(
            isSelected: isSelected,
            expandHorizontally: expandHorizontally,
            action: action,
            label: label
        )
        .background(
            GeometryReader { geo in
                Color.clear.onAppear {
                    buttonFrame = geo.frame(in: .global)
                }
            }
        )
    }
}

struct FloatingMenu<T: Identifiable>: View {
    let items: [T]
    let itemTitle: (T) -> String
    let selectedId: T.ID?
    let onSelect: (T) -> Void
    let alignment: HorizontalAlignment
    @Binding var isExpanded: Bool
    let onExploreMore: (() -> Void)?  // Optional parameter

    // Namespace for matched geometry animations.
    @Namespace private var menuAnimation

    init(
        items: [T],
        itemTitle: @escaping (T) -> String,
        selectedId: T.ID?,
        onSelect: @escaping (T) -> Void,
        alignment: HorizontalAlignment,
        isExpanded: Binding<Bool>,
        onExploreMore: (() -> Void)? = nil  // Default value of nil
    ) {
        self.items = items
        self.itemTitle = itemTitle
        self.selectedId = selectedId
        self.onSelect = onSelect
        self.alignment = alignment
        self._isExpanded = isExpanded
        self.onExploreMore = onExploreMore
    }

    var body: some View {
        // Determine the trigger item – if none is selected, use the first.
        let triggerItem = items.first { $0.id == selectedId } ?? items.first

        VStack(alignment: alignment, spacing: 12) {
            // Trigger button at the top.
            VStack(alignment: alignment, spacing: 0) {
                FloatingMenuButton(
                    action: {
                        withAnimation(.spring(response: 0.4, dampingFraction: 0.8, blendDuration: 0.1)) {
//                            if items.count > 1 || onExploreMore == nil {
                                isExpanded.toggle()
//                            } else {
//                                onExploreMore?()
//                            }
                        }
                    },
                    isSelected: triggerItem?.id == selectedId,
                    expandHorizontally: alignment == .leading
                ) {
                    // When collapsed, apply the matched geometry effect so that a fly‑out item can animate into this spot.
                    // When expanded, show the text normally so it doesn’t disappear.
                    Text(triggerItem.map(itemTitle) ?? "")
                        .if(!isExpanded) { view in
                            view.matchedGeometryEffect(id: "menuItem", in: menuAnimation)
                        }
                }
            }

            // Fly-out list.
            VStack(alignment: alignment, spacing: 12) {
                ForEach(Array(items.filter { $0.id != triggerItem?.id }.enumerated()),
                        id: \.element.id) { index, item in
                    FloatingMenuButton(
                        action: {
                            withAnimation(
                                .spring(response: 0.4, dampingFraction: 0.8, blendDuration: 0.1)
                                    .delay(Double(index) * 0.05)
                            ) {
                                onSelect(item)
                                isExpanded = false
                            }
                        },
                        isSelected: item.id == selectedId,
                        expandHorizontally: alignment == .leading
                    ) {
                        // When expanded, if this is the selected item, attach the matched geometry effect.
                        Text(itemTitle(item))
                            .if(item.id == selectedId && isExpanded) { view in
                                view.matchedGeometryEffect(id: "menuItem", in: menuAnimation)
                            }
                    }
                    .offset(x: isExpanded ? 0 : (alignment == .leading ? -200 : 200))
                    .animation(
                        .spring(response: 0.4, dampingFraction: 0.8, blendDuration: 0.1)
                            .delay(Double(index) * 0.05),
                        value: isExpanded
                    )
                }

                // "Explore More Areas" button.
//                if alignment == .leading && items.count <= 1 && onExploreMore != nil {
//                    FloatingMenuButton(
//                        action: {
//                            withAnimation(
//                                .spring(response: 0.4, dampingFraction: 0.8, blendDuration: 0.0)
//                                    .delay(0.05)
//                            ) {
//                                onExploreMore?()
//                            }
//                        },
//                        expandHorizontally: true
//                    ) {
//                        Text("Explore More Areas")
//                    }
//                    .offset(x: isExpanded ? 0 : -200)
//                    .animation(
//                        .spring(response: 0.4, dampingFraction: 0.8, blendDuration: 0.0)
//                            .delay(0.05),
//                        value: isExpanded
//                    )
//                }
            }
            .clipped() // Hide off-screen content.
            .frame(height: isExpanded ? nil : 0) // Collapse height when not expanded.
        }
        .frame(maxHeight: .infinity, alignment: .top)
    }
}

#Preview("FloatingMenu") {
    struct PreviewItem: Identifiable {
        let id: String
        let name: String
    }

    struct PreviewWrapper: View {
        @State private var leftExpanded = false
        @State private var rightExpanded = false
        @State private var singleExpanded = false
        @State private var leftSelected = "1"
        @State private var rightSelected = "2"

        let items = [
            PreviewItem(id: "1", name: "Dashboard"),
            PreviewItem(id: "2", name: "Reports"),
            PreviewItem(id: "3", name: "Settings")
        ]

        var body: some View {
            ZStack {
                Color.black.ignoresSafeArea()

                VStack(spacing: 40) {
                    // Left-aligned menu.
                    FloatingMenu(
                        items: items,
                        itemTitle: { $0.name },
                        selectedId: leftSelected,
                        onSelect: { item in
                            leftSelected = item.id
                            leftExpanded = false
                        },
                        alignment: .leading,
                        isExpanded: $leftExpanded
                    )

                    // Right-aligned menu.
                    FloatingMenu(
                        items: items,
                        itemTitle: { $0.name },
                        selectedId: rightSelected,
                        onSelect: { item in
                            rightSelected = item.id
                            rightExpanded = false
                        },
                        alignment: .trailing,
                        isExpanded: $rightExpanded
                    )

                    // Single item with explore more.
                    FloatingMenu(
                        items: [items[0]],
                        itemTitle: { $0.name },
                        selectedId: "1",
                        onSelect: { _ in },
                        alignment: .leading,
                        isExpanded: $singleExpanded,
                        onExploreMore: {}
                    )
                }
                .padding()
            }
        }
    }

    return PreviewWrapper()
}

================
File: sightline/sightline/Views/Components/ScanningAnimation.swift
================
import SwiftUI

struct ScanningAnimation: View {
    let namespace: Namespace.ID
    @State private var position: CGFloat = 0.0
    
    var body: some View {
        GeometryReader { geometry in
            let halfHeight = geometry.size.height / 2
            let scanningTop = geometry.size.height * 0.1 - halfHeight
            let scanningBottom = geometry.size.height * 0.9 - halfHeight
            
            ZStack {
                // Scanning line with matched geometry effect.
                Rectangle()
                    .fill(
                        LinearGradient(
                            gradient: Gradient(colors: [
                                .clear,
                                .blue.opacity(0.5),
                                .blue,
                                .blue.opacity(0.5),
                                .clear
                            ]),
                            startPoint: .leading,
                            endPoint: .trailing
                        )
                    )
                    .frame(height: 3)
                    .offset(y: position)
                    .shadow(color: .blue.opacity(0.5), radius: 4)
                    .matchedGeometryEffect(id: "scannerLine", in: namespace)
                
                // Scanner corners with matched geometry effect.
                ScannerCorners()
                    .stroke(Color.white.opacity(0.7), lineWidth: 3)
                    .frame(width: geometry.size.width * 0.8,
                           height: geometry.size.height * 0.7)
                    .position(x: geometry.size.width / 2,
                              y: geometry.size.height / 2)
                    .matchedGeometryEffect(id: "scannerCorners", in: namespace)
                    
            }
            .onAppear {
                position = scanningTop
                withAnimation(
                    .easeInOut(duration: 2.0)
                        .repeatForever(autoreverses: true)
                ) {
                    position = scanningBottom
                }
            }
        }
    }
}

struct ScannerCorners: Shape {
    func path(in rect: CGRect) -> Path {
        var path = Path()
        let cornerLength: CGFloat = 30
        
        // Top left corner
        path.move(to: CGPoint(x: rect.minX, y: rect.minY + cornerLength))
        path.addLine(to: CGPoint(x: rect.minX, y: rect.minY))
        path.addLine(to: CGPoint(x: rect.minX + cornerLength, y: rect.minY))
        
        // Top right corner
        path.move(to: CGPoint(x: rect.maxX - cornerLength, y: rect.minY))
        path.addLine(to: CGPoint(x: rect.maxX, y: rect.minY))
        path.addLine(to: CGPoint(x: rect.maxX, y: rect.minY + cornerLength))
        
        // Bottom right corner
        path.move(to: CGPoint(x: rect.maxX, y: rect.maxY - cornerLength))
        path.addLine(to: CGPoint(x: rect.maxX, y: rect.maxY))
        path.addLine(to: CGPoint(x: rect.maxX - cornerLength, y: rect.maxY))
        
        // Bottom left corner
        path.move(to: CGPoint(x: rect.minX + cornerLength, y: rect.maxY))
        path.addLine(to: CGPoint(x: rect.minX, y: rect.maxY))
        path.addLine(to: CGPoint(x: rect.minX, y: rect.maxY - cornerLength))
        
        return path
    }
}

================
File: sightline/sightline/Views/Components/ScanningTransitionView.swift
================
import SwiftUI

struct ScanningTransitionView: View {
    let namespace: Namespace.ID
    @State private var animateTransition = false
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // Dramatic blue scanning line
                Rectangle()
                    .fill(
                        LinearGradient(
                            gradient: Gradient(colors: [
                                .clear,
                                .blue.opacity(0.9),
                                .blue,
                                .blue.opacity(0.9),
                                .clear
                            ]),
                            startPoint: .leading,
                            endPoint: .trailing
                        )
                    )
                    // Increase the height a lot more then add a scale effect
                    .frame(height: animateTransition ? 100 : 3)
                    .shadow(color: .blue.opacity(animateTransition ? 1.0 : 0.5),
                            radius: animateTransition ? 30 : 4)
                    .matchedGeometryEffect(id: "scannerLine", in: namespace)
                    .opacity(animateTransition ? 0 : 1)
                
                // Drastically expand + rotate the scanner corners
                ScannerCorners()
                    .stroke(Color.white.opacity(0.7), lineWidth: animateTransition ? 1 : 3)
                    .frame(width: animateTransition ? geometry.size.width * 1.5 : geometry.size.width * 0.8,
                           height: animateTransition ? geometry.size.height * 1.5 : geometry.size.height * 0.8)
                    .position(x: geometry.size.width / 2, y: geometry.size.height / 2)
                    .matchedGeometryEffect(id: "scannerCorners", in: namespace)
                    .opacity(animateTransition ? 0 : 1)
            }
            .onAppear {
                // You can adjust the animation duration or add delays to chain effects.
                withAnimation(.easeInOut(duration: 1.2)) {
                    animateTransition = true
                }
            }
        }
        .ignoresSafeArea()
    }
}

================
File: sightline/sightline/Views/ContentFeedView/ContentFeedView.swift
================
import SwiftUI
import UIKit

struct ContentFeedView: View {
    @EnvironmentObject var appState: AppState
    @EnvironmentObject var viewModel: ContentFeedViewModel  // <-- Replaced local @StateObject

    @State private var showingNeighborhoods = false
    @State private var showingCategories = false
    @State private var selectedPlaceId: String? = nil
    
    var body: some View {
        ZStack(alignment: .top) {
            Color.black.ignoresSafeArea()
            
            if viewModel.isLoading {
                LoadingState()
            } else if !viewModel.hasLoadedNeighborhoods {
                LoadingState()
            } else if viewModel.unlockedNeighborhoods.isEmpty {
                EmptyNeighborhoodState()
            } else if viewModel.contentItems.isEmpty {
                Text("No content available")
                    .foregroundColor(.white)
            } else {
                VerticalFeedView(
                    currentIndex: $viewModel.currentIndex,
                    itemCount: viewModel.contentItems.count,
                    onIndexChanged: { index in
                        viewModel.currentIndex = index
                    }
                ) { index in
                    if index < viewModel.contentItems.count {
                        ContentItemView(content: viewModel.contentItems[index])
                            .environmentObject(viewModel)
                            .onTapGesture {
                                let placeIds = viewModel.contentItems[index].placeIds
                                if !placeIds.isEmpty {
                                    selectedPlaceId = placeIds[0]
                                }
                            }
                    } else {
                        Color.black // Fallback view
                    }
                }
                .ignoresSafeArea()
                .zIndex(0)
            }
            
            // Menus
            HStack(alignment: .top) {
                // Neighborhoods Menu
                FloatingMenu(
                    items: viewModel.unlockedNeighborhoods,
                    itemTitle: { $0.name },
                    selectedId: viewModel.selectedNeighborhood?.id,
                    onSelect: { neighborhood in
                        viewModel.selectedNeighborhood = neighborhood
                        showingNeighborhoods = false
                        Task {
                            await viewModel.loadContent()
                        }
                    },
                    alignment: .leading,
                    isExpanded: $showingNeighborhoods,
                    onExploreMore: {
                        appState.shouldSwitchToDiscover = true
                    }
                )
                
                Spacer()
                
                // Categories Menu
                FloatingMenu(
                    items: viewModel.availableCategories,
                    itemTitle: { $0.rawValue.capitalized },
                    selectedId: viewModel.selectedCategory.rawValue,
                    onSelect: { category in
                        viewModel.categorySelected(category)
                        showingCategories = false
                    },
                    alignment: .trailing,
                    isExpanded: $showingCategories
                )
            }
            .padding(.top, 24)
            .padding(.horizontal, 16)
            .zIndex(2)
        }
        .sheet(item: Binding(
            get: {
                selectedPlaceId.map { PlaceDetailPresentation(placeId: $0) }
            },
            set: { presentation in
                selectedPlaceId = presentation?.placeId
            }
        )) { presentation in
            PlaceDetailView(placeId: presentation.placeId)
                .presentationDetents([.medium, .large])
                .presentationDragIndicator(.visible)
                .presentationBackgroundInteraction(.enabled)
        }
        .task {
            if !viewModel.hasLoadedNeighborhoods {
                await viewModel.loadUnlockedNeighborhoods()
                await viewModel.loadContent()
            } else if viewModel.contentItems.isEmpty {
                await viewModel.loadContent()
            } else {
                viewModel.videoManager.currentPlayer?.play()
            }
        }
    }
}

struct LoadingState: View {
    var body: some View {
        GeometryReader { geometry in
            VStack(spacing: 16) {
                ProgressView()
                    .scaleEffect(1.5)
                    .tint(.white)
                
                Text("Loading...")
                    .font(.custom("Baskerville", size: 18))
                    .foregroundColor(.white.opacity(0.8))
            }
            .frame(width: geometry.size.width, height: geometry.size.height)
        }
    }
}

struct EmptyNeighborhoodState: View {
    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                ZStack {
                    // Background Image
                    Image("nocontent")
                        .resizable()
                        .aspectRatio(contentMode: .fill)
                        .frame(width: geometry.size.width, height: geometry.size.height)
                        .clipped()
                        .ignoresSafeArea()
                    
                    // Content Container
                    VStack(spacing: 24) {
                        VStack(spacing: 16) {
                            // Header
                            Text("Unlock Your First Neighborhood")
                                .font(.custom("Baskerville-Bold", size: 28))
                                .multilineTextAlignment(.center)
                            
                            Text("Discover local landmarks to unlock neighborhood content and start exploring stories from your community")
                                .font(.custom("Baskerville", size: 18))
                                .foregroundColor(.secondary)
                                .multilineTextAlignment(.center)
                            
                            Image(systemName: "camera.viewfinder")
                                .font(.system(size: 44))
                                .foregroundColor(.white.opacity(0.8))
                                .padding(.top, 8)
                        }
                        .padding(24)
                        .background(.ultraThinMaterial)
                        .cornerRadius(16)
                        .shadow(radius: 8)
                    }
                    .padding()
                }
                .frame(minHeight: geometry.size.height)
            }
            .ignoresSafeArea(edges: .top)
        }
        .ignoresSafeArea(edges: .top)
    }
}

struct CategoryPill: View {
    let title: String
    let isSelected: Bool
    
    var body: some View {
        Text(title)
            .padding(.horizontal, 16)
            .padding(.vertical, 8)
            .background(isSelected ? Color.white : Color.white.opacity(0.2))
            .foregroundColor(isSelected ? .black : .white)
            .cornerRadius(20)
    }
}

struct PlaceDetailPresentation: Identifiable {
    let id = UUID()
    let placeId: String
}

================
File: sightline/sightline/Views/ContentFeedView/ContentFeedViewModel.swift
================
import SwiftUI
import FirebaseFirestore
import FirebaseAuth
import Combine

enum NavigationDestination: Hashable {
    case placeDetail(placeId: String, initialContentId: String)
}

@MainActor
final class ContentFeedViewModel: ObservableObject {
    @Published var unlockedNeighborhoods: [Neighborhood] = []
    @Published var selectedNeighborhood: Neighborhood?
    @Published var selectedCategory: FilterCategory = .restaurant
    @Published var availableCategories: [FilterCategory] = []
    @Published var contentItems: [Content] = []
    
    // When currentIndex changes we now start an async task.
    @Published var currentIndex: Int = 0 {
        didSet {
            Task {
                await updateActiveVideo()
            }
        }
    }
    @Published var isLoading = false
    @Published var places: [String: Place] = [:] // Cache of places by ID
    
    @Published private(set) var hasLoadedNeighborhoods = false
    
    let videoManager = VideoPlayerManager()
    private let services = ServiceContainer.shared

    /// This async function centralizes the video activation logic.
    func updateActiveVideo() async {
        guard !contentItems.isEmpty,
              currentIndex >= 0,
              currentIndex < contentItems.count
        else { return }
        
        let urls = contentItems.map { $0.videoUrl }
        videoManager.preloadVideos(for: urls, at: currentIndex)
        
        await videoManager.activatePlayerAsync(for: contentItems[currentIndex].videoUrl)
    }
    
    func loadUnlockedNeighborhoods() async {
        // Update the loading state tracking
        DispatchQueue.main.async {
            self.isLoading = true
            self.hasLoadedNeighborhoods = false
        }
        
        // First try to load from preloaded data
        if let data = UserDefaults.standard.data(forKey: "preloadedNeighborhoods"),
           let neighborhoods = try? JSONDecoder().decode([Neighborhood].self, from: data) {
            self.unlockedNeighborhoods = neighborhoods
            if self.selectedNeighborhood == nil {
                self.selectedNeighborhood = neighborhoods.first
            }
            DispatchQueue.main.async {
                self.hasLoadedNeighborhoods = true
                self.isLoading = false
            }
            return
        }
        
        // Fall back to loading from Firestore
        guard let userId = services.auth.userId else { return }
        
        do {
            let neighborhoods = try await services.firestore.fetchUnlockedNeighborhoods(for: userId)
            self.unlockedNeighborhoods = neighborhoods
            if self.selectedNeighborhood == nil {
                self.selectedNeighborhood = neighborhoods.first
            }
            DispatchQueue.main.async {
                self.hasLoadedNeighborhoods = true
                self.isLoading = false
            }
        } catch {
            print("Error loading neighborhoods: \(error)")
            DispatchQueue.main.async {
                self.hasLoadedNeighborhoods = true
                self.isLoading = false
            }
        }
    }
    
    private func loadAvailableCategories() async {
        guard let neighborhood = selectedNeighborhood else { return }
        
        // First try to load from preloaded data for the first neighborhood
        if let firstNeighborhood = unlockedNeighborhoods.first,
           neighborhood.id == firstNeighborhood.id,  // Compare by ID instead
           let data = UserDefaults.standard.data(forKey: "preloadedCategories"),
           let categories = try? JSONDecoder().decode([FilterCategory].self, from: data) {
            self.availableCategories = categories
            if !categories.contains(selectedCategory) && !categories.isEmpty {
                selectedCategory = categories[0]
            }
            return
        }
        
        // Fall back to loading from Firestore
        do {
            let categories = try await services.firestore.fetchAvailableCategories(
                for: neighborhood.id!
            )
            self.availableCategories = categories
            
            if !categories.contains(selectedCategory) && !categories.isEmpty {
                selectedCategory = categories[0]
                await loadContent()
            }
        } catch {
            print("❌ Error loading available categories: \(error)")
        }
    }

    func loadContent() async {
        guard let neighborhood = selectedNeighborhood else {
            print("❌ No neighborhood selected")
            return
        }
        
        isLoading = true
        do {
            await loadAvailableCategories()
            
            print("🔄 Loading content for neighborhood: \(neighborhood.name), category: \(selectedCategory.rawValue)")
            
            let content = try await services.firestore.fetchContentByCategory(
                category: selectedCategory,
                neighborhoodId: neighborhood.id!
            )
            
            // Fetch places for all content items
            var placeMap: [String: Place] = [:]
            for item in content {
                for placeId in item.placeIds {
                    do {
                        let place = try await services.firestore.fetchPlace(id: placeId)
                        placeMap[placeId] = place
                    } catch {
                        print("Error loading place \(placeId): \(error)")
                    }
                }
            }

            self.contentItems = content
            self.places = placeMap
            print("✅ Loaded \(content.count) content items")
            
            // Force preload current index first
            if !content.isEmpty {
                let urls = content.map { $0.videoUrl }
                videoManager.preloadVideos(for: urls, at: 0)
                await videoManager.activatePlayerAsync(for: content[0].videoUrl)
            }
            
            isLoading = false
        } catch {
            print("❌ Error loading content: \(error)")
            isLoading = false
        }
    }
    
    // Called when category changes
    func categorySelected(_ category: FilterCategory) {
        selectedCategory = category
        self.currentIndex = 0  // Will trigger updateActiveVideo automatically.
        Task {
            await loadContent()
        }
    }
}

================
File: sightline/sightline/Views/CameraView.swift
================
import SwiftUI
import AVFoundation

class CameraController: NSObject, ObservableObject {
    @Published var isAuthorized = false
    @Published var error: String?
    @Published var isCapturing = false
    
    var captureSession: AVCaptureSession?
    private var videoOutput = AVCaptureVideoDataOutput()
    private var frameCount = 0
    private let maxFrames = 10
    private var captureStartTime: Date?
    private var lastCaptureTime: Date?
    private var onFrameCaptured: ((UIImage) -> Void)?
    
    override init() {
        super.init()
        checkPermissions()
    }
    
    func checkPermissions() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            self.isAuthorized = true
            setupCamera()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.isAuthorized = granted
                    if granted {
                        self?.setupCamera()
                    }
                }
            }
        case .denied, .restricted:
            self.isAuthorized = false
            self.error = "Camera access is denied. Please enable it in Settings."
        @unknown default:
            self.isAuthorized = false
            self.error = "Unknown camera authorization status"
        }
    }
    
    private func setupCamera() {
        let session = AVCaptureSession()
        session.sessionPreset = .medium
        
        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
              let input = try? AVCaptureDeviceInput(device: device) else {
            error = "Failed to initialize camera"
            return
        }
        
        if session.canAddInput(input) {
            session.addInput(input)
        }
        
        videoOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "camera.frame.processing"))
        
        if session.canAddOutput(videoOutput) {
            session.addOutput(videoOutput)
        }
        
        captureSession = session
    }
    
    func startCapturing(onFrameCaptured: @escaping (UIImage) -> Void) {
        self.onFrameCaptured = onFrameCaptured
        self.frameCount = 0
        self.lastCaptureTime = nil
        self.captureStartTime = Date()
        self.isCapturing = true
        
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.captureSession?.startRunning()
        }
    }
    
    func stopCapturing() {
        self.isCapturing = false
        self.onFrameCaptured = nil
        
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.captureSession?.stopRunning()
        }
    }
}

extension CameraController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard isCapturing && frameCount < maxFrames else { return }
        
        let now = Date()
        
        if frameCount == 0 {
            guard let startTime = captureStartTime, now.timeIntervalSince(startTime) >= 3.0 else {
                return
            }
        } else {
            let requiredInterval: TimeInterval = frameCount < 5 ? 1.0 : 2.0
            guard let lastTime = lastCaptureTime, now.timeIntervalSince(lastTime) >= requiredInterval else {
                return
            }
        }
        
        guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer),
              let onFrameCaptured = onFrameCaptured else {
            return
        }
        
        let ciImage = CIImage(cvPixelBuffer: imageBuffer)
        let context = CIContext()
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else { return }
        let image = UIImage(cgImage: cgImage)
        
        DispatchQueue.main.async {
            self.frameCount += 1
            self.lastCaptureTime = now
            onFrameCaptured(image)
            
            if self.frameCount >= self.maxFrames {
                self.stopCapturing()
            }
        }
    }
}

struct CameraPreviewView: UIViewRepresentable {
    let session: AVCaptureSession
    
    func makeUIView(context: Context) -> UIView {
        let view = UIView(frame: UIScreen.main.bounds)
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.frame = view.frame
        previewLayer.videoGravity = .resizeAspectFill
        view.layer.addSublayer(previewLayer)
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {}
}

// Updated CameraView with flash overlay effect added.
struct CameraView: View {
  @StateObject private var cameraController = CameraController()
  @Environment(\.dismiss) private var dismiss
  var onFrameCaptured: (UIImage) -> Void
  @Binding var shouldFlash: Bool
  
  @State private var flashOverlayOpacity: Double = 0.0
  
  var body: some View {
    GeometryReader { geometry in
      ZStack { if let session = cameraController.captureSession {
        CameraPreviewView(session: session)
        // Scanning overlay while capturing
        if cameraController.isCapturing {
          VStack {
            Spacer()
            Text("Scanning for landmarks...")
              .foregroundColor(.white)
              .padding()
              .background(Color.black.opacity(0.7))
              .cornerRadius(10)
            Spacer().frame(height: 160)
          }
        }
        
        if let error = cameraController.error {
          Text(error)
            .foregroundColor(.red)
            .padding()
            .background(Color.black.opacity(0.7))
            .cornerRadius(10)
        }
        
        // Flash overlay effect
        Color.white
          .opacity(flashOverlayOpacity)
          .ignoresSafeArea()
        
        
      }
      }
      .ignoresSafeArea(.all, edges: .all)
      .onChange(of: shouldFlash) { newValue in
        if newValue {
          // Trigger flash animation
          withAnimation(.easeIn(duration: 0.1)) {
            flashOverlayOpacity = 1.0
          }
          withAnimation(.easeOut(duration: 0.3).delay(0.1)) {
            flashOverlayOpacity = 0.0
          }
          // Reset the flag
          DispatchQueue.main.asyncAfter(deadline: .now() + 0.4) {
            shouldFlash = false
          }
        }
      }
      .onAppear {
        cameraController.startCapturing { image in
          onFrameCaptured(image)
        }
      }
      .onDisappear {
        cameraController.stopCapturing()
      }
    }
  }
}
#if DEBUG
// Mock preview view that replaces camera feed with a color
private struct MockCameraPreviewView: View {
    var body: some View {
        Color.gray // Simulates camera view
    }
}

struct CameraView_Previews: PreviewProvider {
    static var previews: some View {
        CameraView(
            onFrameCaptured: { _ in },
            shouldFlash: .constant(false)
        )
        .previewDisplayName("Camera View")
        
        // Preview with flash effect
        CameraView(
            onFrameCaptured: { _ in },
            shouldFlash: .constant(true)
        )
        .previewDisplayName("With Flash")
    }
}
#endif

================
File: sightline/sightline/Views/ContentItemView.swift
================
import SwiftUI
import AVKit
import FirebaseStorage

@MainActor
struct ContentItemView: View {
    @EnvironmentObject var appState: AppState
    @EnvironmentObject var feedViewModel: ContentFeedViewModel
    let content: Content
    @StateObject private var viewModel: ContentItemViewModel
    @Environment(\.safeAreaInsets) private var safeAreaInsets
    
    init(content: Content) {
        self.content = content
        _viewModel = StateObject(wrappedValue: ContentItemViewModel(
            content: content,
            services: ServiceContainer.shared
        ))
    }
    
    var body: some View {
        GeometryReader { geo in
            ZStack {
                if let player = feedViewModel.videoManager.playerFor(url: content.videoUrl) {
                    VideoPlayer(player: player)
                        .edgesIgnoringSafeArea(.all)
                        .frame(width: geo.size.width, height: geo.size.height + safeAreaInsets.top + safeAreaInsets.bottom)
                        .offset(y: -safeAreaInsets.top)
                } else if feedViewModel.videoManager.error != nil {
                    Color.black
                    VStack {
                        Image(systemName: "exclamationmark.triangle")
                            .font(.largeTitle)
                            .foregroundColor(.yellow)
                        Text("Failed to load video")
                            .foregroundColor(.white)
                    }
                } else {
                    Color.black
                    ProgressView()
                        .scaleEffect(1.5)
                }
                
                // Overlay info - restructured
                VStack {
                    Spacer()
                    
                    // Content info overlay
                    VStack(spacing: 8) {
                        HStack {
                            VStack(alignment: .leading, spacing: 8) {
                                Text(content.caption)
                                    .font(.headline)
                                    .foregroundColor(.white)
                                    .multilineTextAlignment(.leading)
                                
                                NavigationLink(value: AppState.NavigationDestination.placeDetail(placeId: content.placeIds[0], initialContentId: content.id)) {
                                    Text(viewModel.placeName ?? "Loading place...")
                                        .font(.subheadline)
                                        .foregroundColor(.white)
                                        .padding(.horizontal, 12)
                                        .padding(.vertical, 6)
                                        .background(.ultraThinMaterial)
                                        .cornerRadius(16)
                                }
                            }
                            Spacer()
                        }
                        .padding(.horizontal)
                        .padding(.bottom, 120) // Increased bottom padding to bring content up higher
                    }
                    .background(
                        LinearGradient(
                            gradient: Gradient(colors: [.clear, .black.opacity(0.3)]),
                            startPoint: .top,
                            endPoint: .bottom
                        )
                        .padding(.top, -100) // Extend gradient upward
                    )
                }
            }
        }
        .onAppear {
            Task {
                await viewModel.loadPlace()
            }
        }
    }
}

@MainActor
final class ContentItemViewModel: ObservableObject {
    @Published var placeName: String?
    @Published var isLoadingPlace = true
    private let content: Content
    private let services: ServiceContainer
    
    init(content: Content, services: ServiceContainer) {
        self.content = content
        self.services = services
    }
    
    func loadPlace() async {
        isLoadingPlace = true
        do {
            let place = try await services.firestore.fetchPlace(id: content.placeIds[0])
            await MainActor.run {
                self.placeName = place.name
            }
        } catch {
            await handlePlaceLoadError(error)
        }
        isLoadingPlace = false
    }
    
    private func handlePlaceLoadError(_ error: Error) async {
        await MainActor.run {
            // Update state for error display
            print("🔴 Critical place load error: \(error.localizedDescription)")
        }
    }
    
    func cleanup() {
        // No longer needed as video management is handled by VideoPlayerManager
    }
}

// Add this extension to get safe area insets in SwiftUI
private extension EnvironmentValues {
    var safeAreaInsets: EdgeInsets {
        (UIApplication.shared.windows.first?.safeAreaInsets ?? .zero).insets
    }
}

private extension UIEdgeInsets {
    var insets: EdgeInsets {
        EdgeInsets(top: top, leading: left, bottom: bottom, trailing: right)
    }
}

================
File: sightline/sightline/Views/MainTabView.swift
================
import SwiftUI
import FirebaseAuth

struct MainTabView: View {
    @StateObject private var appState = AppState()
    @State private var selectedTab = 0
    @StateObject private var feedViewModel = ContentFeedViewModel()
    private let services = ServiceContainer.shared
    
    var body: some View {
        TabView(selection: $selectedTab) {
            // Camera/Detection Tab
            LandmarkDetectionView()
                .environmentObject(appState)
                .tabItem {
                    Label("Discover", systemImage: "camera.viewfinder")
                }
                .tag(0)
            
            // Content Feed Tab
            ContentFeedView()
                .environmentObject(appState)
                .environmentObject(feedViewModel)
                .tabItem {
                    Label("Feed", systemImage: "play.square.stack")
                }
                .tag(1)
                
            // Profile Tab
            ProfileView()
                .environmentObject(appState)
                .tabItem {
                    Label("Profile", systemImage: "person.circle")
                }
                .tag(2)
        }
        .tint(.white)  // Makes the selected tab white
        .onAppear {
            // Style the unselected tabs to be more visible
            let appearance = UITabBarAppearance()
            appearance.configureWithOpaqueBackground()
            appearance.backgroundColor = UIColor.black
            
            // Style the unselected items
            appearance.stackedLayoutAppearance.normal.iconColor = .gray
            appearance.stackedLayoutAppearance.normal.titleTextAttributes = [.foregroundColor: UIColor.gray]
            
            // Style the selected items
            appearance.stackedLayoutAppearance.selected.iconColor = .white
            appearance.stackedLayoutAppearance.selected.titleTextAttributes = [.foregroundColor: UIColor.white]
            
            UITabBar.appearance().standardAppearance = appearance
            if #available(iOS 15.0, *) {
                UITabBar.appearance().scrollEdgeAppearance = appearance
            }
        }
        .task {
            do {
                try await services.auth.signInAnonymously()
            } catch {
                print("Failed to sign in: \(error)")
            }
        }
        // Switch to Feed when requested
        .onChange(of: appState.shouldSwitchToFeed) { oldValue, newValue in
            if newValue {
                withAnimation {
                    selectedTab = 1
                }
                appState.shouldSwitchToFeed = false
            }
        }
        // Pause video if leaving feed
        .onChange(of: selectedTab) { oldValue, newValue in
            if oldValue == 1 && newValue != 1 {
                // Instead of cleaning up state, just pause the current video.
                feedViewModel.videoManager.currentPlayer?.pause()
            }
        }
        // Switch to Profile when requested
        .onChange(of: appState.shouldSwitchToProfile) { oldValue, newValue in
            if newValue {
                withAnimation {
                    selectedTab = 2
                }
                appState.shouldSwitchToProfile = false
            }
        }
    }
}

================
File: sightline/sightline/Views/PlaceDetailView.swift
================
import SwiftUI
import MapKit
import FirebaseFirestore
import FirebaseAuth
import os

struct PlaceDetailView: View {
    let placeId: String
    @StateObject private var viewModel: PlaceDetailViewModel
    @Environment(\.dismiss) private var dismiss
    @EnvironmentObject private var appState: AppState  // for navigation
    
    // Add state for sheet height
    @State private var sheetHeight: CGFloat = UIScreen.main.bounds.height * 0.7
    @State private var offset: CGFloat = 0

    @State private var region = MKCoordinateRegion(
        center: CLLocationCoordinate2D(latitude: 30.0, longitude: -97.0),
        span: MKCoordinateSpan(latitudeDelta: 0.05, longitudeDelta: 0.05)
    )

    // Add error state
    @State private var showError = false

    private let logger = Logger(subsystem: Bundle.main.bundleIdentifier ?? "Sightline", category: "PlaceDetailView")

    init(placeId: String) {
        self.placeId = placeId
        _viewModel = StateObject(wrappedValue: PlaceDetailViewModel())
    }

    func openDirections() {
        guard let place = viewModel.place else { return }
        
        let coordinates = "\(place.coordinates.latitude),\(place.coordinates.longitude)"
        let name = place.name.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? ""
        let url = URL(string: "http://maps.apple.com/?daddr=\(coordinates)&name=\(name)")
        
        if let url = url, UIApplication.shared.canOpenURL(url) {
            UIApplication.shared.open(url)
        } else {
            viewModel.errorMessage = "Unable to open Maps"
        }
    }
    
    var directionsButton: some View {
        Button(action: openDirections) {
            HStack {
                Image(systemName: "map.fill")
                Text("Get Directions")
            }
            .foregroundColor(.white)
            .padding(.vertical, 12)
            .padding(.horizontal, 24)
            .background(Color.blue)
            .cornerRadius(10)
        }
        .disabled(viewModel.place == nil)
        .opacity(viewModel.place == nil ? 0.6 : 1.0)
    }
    
    var savePlaceButton: some View {
        Button(action: {
            Task {
                await viewModel.savePlace()
                // After saving, navigate to Profile tab
                appState.shouldSwitchToProfile = true
                dismiss()
            }
        }) {
            HStack {
                Image(systemName: "heart.fill")
                Text("Save Place")
            }
            .foregroundColor(.white)
            .padding(.vertical, 12)
            .padding(.horizontal, 24)
            .background(Color.pink)
            .cornerRadius(10)
        }
        .disabled(viewModel.place == nil)
        .opacity(viewModel.place == nil ? 0.6 : 1.0)
    }

    var mapView: some View {
        Group {
            if let place = viewModel.place {
                Map(coordinateRegion: $region, annotationItems: [place]) { place in
                    MapMarker(
                        coordinate: CLLocationCoordinate2D(
                            latitude: place.coordinates.latitude,
                            longitude: place.coordinates.longitude
                        ),
                        tint: .red
                    )
                }
                .onAppear {
                    // More defensive region initialization
                    let coordinate = CLLocationCoordinate2D(
                        latitude: place.coordinates.latitude,
                        longitude: place.coordinates.longitude
                    )
                    if CLLocationCoordinate2DIsValid(coordinate) {
                        region = MKCoordinateRegion(
                            center: coordinate,
                            span: MKCoordinateSpan(latitudeDelta: 0.01, longitudeDelta: 0.01)
                        )
                    } else {
                        logger.warning("Invalid coordinates for place: \(place.id)")
                    }
                }
                .frame(height: 200)
                .cornerRadius(12)
                .padding(.horizontal)
            } else {
                ProgressView()
                    .frame(height: 200)
            }
        }
    }

    var headerView: some View {
        Text(viewModel.place?.name ?? "Loading...")
            .font(.title2)
            .fontWeight(.bold)
            .frame(maxWidth: .infinity)  // Centers the text
            .padding(.top, 16)           // More breathing room above
            .padding(.bottom, 8)         // Consistent padding below
    }

    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                VStack(spacing: 16) {
                    headerView
                    
                    if let errorMessage = viewModel.errorMessage {
                        Text(errorMessage)
                            .foregroundColor(.red)
                            .padding(.horizontal)
                    }

                    // Description area
                    Text(viewModel.place?.description ?? "No description available.")
                        .font(.body)
                        .padding(.horizontal)

                    mapView
                    
                    directionsButton
                    savePlaceButton
                }
            }
            .frame(maxWidth: geometry.size.width)
            .background(.ultraThinMaterial)  // Translucent material background
            .clipShape(RoundedRectangle(cornerRadius: 20, style: .continuous))
        }
        .presentationDetents([
            .height(400),
            .large
        ])
        .presentationDragIndicator(.visible)
        .presentationBackgroundInteraction(.enabled)
        .presentationBackground(.ultraThinMaterial)  // Makes the whole sheet translucent
        .onAppear {
            Task {
                await viewModel.loadPlaceDetails(placeId: placeId)
            }
        }
    }
}

@MainActor
final class PlaceDetailViewModel: ObservableObject {
    @Published var place: Place?
    @Published var errorMessage: String?
    
    private let services = ServiceContainer.shared
    private let logger = Logger(subsystem: Bundle.main.bundleIdentifier ?? "Sightline", category: "PlaceDetailView")

    func loadPlaceDetails(placeId: String) async {
        do {
            let fetchedPlace = try await services.firestore.fetchPlace(id: placeId)
            await MainActor.run {
                self.place = fetchedPlace
                self.errorMessage = nil
            }
        } catch {
            logger.error("Error loading place details: \(error.localizedDescription)")
            await MainActor.run {
                self.errorMessage = "Unable to load place details"
            }
        }
    }
    
    func savePlace() async {
        guard let place = self.place,
              let userId = Auth.auth().currentUser?.uid else { return }
        
        do {
            try await services.firestore.savePlaceForUser(userId: userId, placeId: place.id)
        } catch {
            self.errorMessage = "Error saving place: \(error.localizedDescription)"
        }
    }
}

================
File: sightline/sightline/Views/ProfileView.swift
================
import SwiftUI
import FirebaseAuth

struct ProfileView: View {
    @EnvironmentObject private var appState: AppState
    @StateObject private var viewModel = ProfileViewModel()
    
    var body: some View {
        ZStack {
            if viewModel.isLoading {
                ProgressView()
            } else if viewModel.isAnonymous {
                AuthView(viewModel: viewModel)
            } else {
                UserProfileView(viewModel: viewModel)
                    .navigationTitle("Profile")
            }
        }
        .onAppear {
            viewModel.checkAuthState()
        }
    }
}

// Combined Auth View that handles both Sign Up and Sign In
struct AuthView: View {
    @ObservedObject var viewModel: ProfileViewModel
    @State private var isSignIn = false
    @State private var email = ""
    @State private var password = ""
    @State private var confirmPassword = ""
    
    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                ZStack {
                    // Background Image
                    Image("profile-bg")
                        .resizable()
                        .aspectRatio(contentMode: .fill)
                        .frame(width: geometry.size.width, height: geometry.size.height)
                        .clipped()
                        .ignoresSafeArea()
                    
                    // Content
                    VStack(spacing: 24) {
                        VStack(spacing: 24) {
                            // Header
                            VStack(spacing: 8) {
                                Text(isSignIn ? "Sign In" : "Create an Account")
                                    .font(.custom("Baskerville-Bold", size: 28))
                                
                                if viewModel.hasPendingSavedPlaces {
                                    Text("Sign up to save your places!")
                                        .font(.custom("Baskerville", size: 18))
                                        .foregroundColor(.yellow)
                                        .multilineTextAlignment(.center)
                                        .padding(.horizontal)
                                } else {
                                    Text(isSignIn ? "Welcome Back" : "Save Places, Post Content, and More")
                                        .font(.custom("Baskerville", size: 18))
                                        .foregroundColor(.secondary)
                                        .multilineTextAlignment(.center)
                                }
                            }
                            
                            // Form
                            VStack(spacing: 16) {
                                TextField("Email", text: $email)
                                    .textContentType(.emailAddress)
                                    .keyboardType(.emailAddress)
                                    .autocapitalization(.none)
                                    .foregroundColor(.black)
                                    .customTextField()
                                
                                SecureField("Password", text: $password)
                                    .textContentType(isSignIn ? .password : .newPassword)
                                    .foregroundColor(.black)
                                    .customTextField()
                                    
                                
                                if !isSignIn {
                                    SecureField("Confirm Password", text: $confirmPassword)
                                        .textContentType(.newPassword)
                                        .customTextField()
                                }
                            }
                            
                            if let error = viewModel.errorMessage {
                                Text(error)
                                    .foregroundColor(.red)
                                    .font(.caption)
                                    .padding(.horizontal)
                            }
                            
                            Button(action: {
                                Task {
                                    if isSignIn {
                                        await viewModel.signIn(email: email, password: password)
                                    } else {
                                        await viewModel.signUp(email: email, password: password, confirmPassword: confirmPassword)
                                    }
                                }
                            }) {
                                if viewModel.isProcessing {
                                    ProgressView()
                                        .progressViewStyle(CircularProgressViewStyle(tint: .white))
                                } else {
                                    Text(isSignIn ? "Sign In" : "Create Account")
                                        .frame(maxWidth: .infinity)
                                        .foregroundColor(.white)
                                }
                            }
                            .padding()
                            .background(Color.yellow)
                            .cornerRadius(10)
                            .disabled(viewModel.isProcessing)
                            
                            // Toggle between Sign In and Sign Up
                            Button(action: {
                                withAnimation {
                                    isSignIn.toggle()
                                    viewModel.errorMessage = nil
                                }
                            }) {
                                Text(isSignIn ? "Need an account? Sign Up" : "Already have an account? Sign In")
                                    .foregroundColor(.white)
                                    .underline()
                            }
                        }
                        .padding(24)
                        .background(.ultraThinMaterial)
                        .cornerRadius(16)
                        .shadow(radius: 8)
                      
                      
                          Button(action: {
                              Task {
                                  await viewModel.resetAccount()
                              }
                          }) {
                              Text("Reset Account")
                                  .frame(maxWidth: .infinity)
                                  .padding()
                                  .background(Color.red.opacity(0.9))
                                  .foregroundColor(.white)
                                  .cornerRadius(10)
                          }
                      }
                    
                    .padding()
                }
                .frame(minHeight: geometry.size.height)
            }
            .scrollDismissesKeyboard(.interactively)
            .ignoresSafeArea(edges: .top)
        }
        .ignoresSafeArea(edges: .top)
    }
}

// User Profile View
struct UserProfileView: View {
    @ObservedObject var viewModel: ProfileViewModel
    
    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                ZStack {
                    // Background Image
                    Image("profile-bg")
                        .resizable()
                        .aspectRatio(contentMode: .fill)
                        .frame(width: geometry.size.width, height: geometry.size.height)
                        .clipped()
                        .ignoresSafeArea()
                    
                    // Content
                    VStack(spacing: 24) {
                        // Profile Container
                        VStack(spacing: 20) {
                            // Avatar and Email
                            VStack(spacing: 12) {
                                Image(systemName: "person.circle.fill")
                                    .resizable()
                                    .frame(width: 80, height: 80)
                                    .foregroundColor(.white)
                                
                                Text(viewModel.userEmail ?? "")
                                    .font(.headline)
                            }
                            
                            Divider()
                                .background(.white.opacity(0.5))
                            
                            // Stats or other info could go here
                            HStack(spacing: 32) {
                                StatView(title: "Places", value: "0")
                                StatView(title: "Posts", value: "0")
                                StatView(title: "Likes", value: "0")
                            }
                        }
                        .padding(24)
                        .background(.ultraThinMaterial)
                        .cornerRadius(16)
                        .shadow(radius: 8)
                        
                        // Actions Container
                        VStack(spacing: 16) {
                            // Saved Places Section
                            if !viewModel.savedPlaces.isEmpty {
                                VStack(alignment: .leading, spacing: 10) {
                                    Text("Saved Places")
                                        .font(.title3)
                                        .fontWeight(.bold)
                                    
                                    ForEach(viewModel.savedPlaces, id: \.id) { place in
                                        VStack(alignment: .leading) {
                                            Text(place.name)
                                                .font(.subheadline)
                                                .fontWeight(.semibold)
                                            Text(place.address)
                                                .font(.caption)
                                                .foregroundColor(.secondary)
                                        }
                                        .padding(.vertical, 8)
                                        Divider()
                                    }
                                }
                                .padding()
                                .background(.ultraThinMaterial)
                                .cornerRadius(12)
                            }
                            
                            Button(action: {
                                Task {
                                    await viewModel.signOut()
                                }
                            }) {
                                Text("Sign Out")
                                    .frame(maxWidth: .infinity)
                                    .padding()
                                    .background(Color.red.opacity(0.8))
                                    .foregroundColor(.white)
                                    .cornerRadius(10)
                            }
                            
                        }
                        .padding(24)
                        .background(.ultraThinMaterial)
                        .cornerRadius(16)
                        .shadow(radius: 8)
                        
                    }
                    .padding()
                }
                .frame(minHeight: geometry.size.height)
            }
            .scrollDismissesKeyboard(.interactively)
            .ignoresSafeArea(edges: .top)
        }
        .ignoresSafeArea(edges: .top)
        .onAppear {
            Task {
                await viewModel.loadSavedPlaces()
            }
        }
    }
}

// Helper Views
struct StatView: View {
    let title: String
    let value: String
    
    var body: some View {
        VStack(spacing: 4) {
            Text(value)
                .font(.headline)
            Text(title)
                .font(.caption)
                .foregroundColor(.secondary)
        }
    }
}

@MainActor
class ProfileViewModel: ObservableObject {
    @Published var isLoading = true
    @Published var isAnonymous = true
    @Published var isProcessing = false
    @Published var errorMessage: String?
    @Published var userEmail: String?
    
    // New: maintain a list of saved Places for display
    @Published var savedPlaces: [Place] = []
    
    @Published var hasPendingSavedPlaces = false
    
    private let auth = ServiceContainer.shared.auth
    private let firestoreService = ServiceContainer.shared.firestore
    
    func checkAuthState() {
        if let user = Auth.auth().currentUser {
            isAnonymous = user.isAnonymous
            userEmail = user.email
            
            // Check for pending saved places if anonymous
            if user.isAnonymous {
                Task {
                    await checkPendingSavedPlaces()
                }
            }
        }
        isLoading = false
    }
    
    private func checkPendingSavedPlaces() async {
        guard let userId = Auth.auth().currentUser?.uid else { return }
        do {
            let placeIds = try await firestoreService.fetchSavedPlaceIds(for: userId)
            await MainActor.run {
                self.hasPendingSavedPlaces = !placeIds.isEmpty
            }
        } catch {
            print("Error checking pending saved places: \(error)")
        }
    }
    
    func signUp(email: String, password: String, confirmPassword: String) async {
        guard !isProcessing else { return }
        guard !email.isEmpty else {
            errorMessage = "Please enter an email"
            return
        }
        guard password == confirmPassword else {
            errorMessage = "Passwords don't match"
            return
        }
        guard password.count >= 6 else {
            errorMessage = "Password must be at least 6 characters"
            return
        }
        
        isProcessing = true
        errorMessage = nil
        
        do {
            // Link anonymous account with email/password
            if let user = Auth.auth().currentUser {
                let credential = EmailAuthProvider.credential(withEmail: email, password: password)
                try await user.link(with: credential)
                isAnonymous = false
                userEmail = email
            }
        } catch {
            errorMessage = error.localizedDescription
        }
        
        isProcessing = false
    }
    
    func signOut() async {
        do {
            try await auth.signOut()
            // After signing out, Firebase will automatically sign in anonymously
            // due to our app initialization
            isAnonymous = true
            userEmail = nil
            savedPlaces.removeAll()
        } catch {
            errorMessage = "Failed to sign out"
        }
    }
    
    func signIn(email: String, password: String) async {
        guard !isProcessing else { return }
        guard !email.isEmpty else {
            errorMessage = "Please enter an email"
            return
        }
        guard !password.isEmpty else {
            errorMessage = "Please enter a password"
            return
        }
        
        isProcessing = true
        errorMessage = nil
        
        do {
            let result = try await Auth.auth().signIn(withEmail: email, password: password)
            isAnonymous = false
            userEmail = result.user.email
        } catch {
            errorMessage = error.localizedDescription
        }
        
        isProcessing = false
    }
    
    func resetAccount() async {
        print("🔄 Starting account reset...")
        do {
            print("📤 Attempting to sign out current user...")
            try await auth.signOut()
            print("✅ Sign out successful")
            
            print("🗑️ Clearing UserDefaults...")
            UserDefaults.standard.removePersistentDomain(forName: Bundle.main.bundleIdentifier!)
            print("✅ UserDefaults cleared")
            
            // Clear any other app state/cache as needed
            print("🔄 Resetting view model state...")
            isAnonymous = true
            userEmail = nil
            errorMessage = nil
            savedPlaces.removeAll()
            print("✅ View model state reset")
            
            print("⏳ Waiting for Firebase to auto-create anonymous user...")
            try await Task.sleep(nanoseconds: 1_000_000_000) // 1 second delay
            
            if let currentUser = Auth.auth().currentUser {
                print("✅ New user state: anonymous=\(currentUser.isAnonymous), email=\(currentUser.email ?? "")")
            } else {
                print("⚠️ No current user after reset")
            }
        } catch {
            print("❌ Reset failed with error: \(error.localizedDescription)")
            errorMessage = "Failed to reset account: \(error.localizedDescription)"
        }
    }
    
    // Fetch the user's saved places from Firestore
    func loadSavedPlaces() async {
        guard let userId = Auth.auth().currentUser?.uid, !isAnonymous else { return }
        do {
            let placeIds = try await firestoreService.fetchSavedPlaceIds(for: userId)
            var fetched: [Place] = []
            for pid in placeIds {
                do {
                    let place = try await firestoreService.fetchPlace(id: pid)
                    fetched.append(place)
                } catch {
                    print("Failed to fetch place (\(pid)): \(error)")
                }
            }
            // Sort or manipulate as needed
            await MainActor.run {
                self.savedPlaces = fetched
            }
        } catch {
            print("Error fetching saved places: \(error)")
        }
    }
}

struct ProfileView_Previews: PreviewProvider {
    static var previews: some View {
        ProfileView()
            .environmentObject(AppState())
    }
}

// Helper View Extension
extension View {
    
    func customTextField() -> some View {
        self
            .textFieldStyle(.plain)
            .padding(12)
            .background(Color.white)
            .accentColor(Color.yellow)
            .tint(Color.black)
            .cornerRadius(8)
    }
}

================
File: sightline/sightline/Views/SplashView.swift
================
import SwiftUI

struct SplashView: View {
    @State private var progress: CGFloat = 0
    @State private var opacity: Double = 1
    let onFinished: () -> Void
    
    var body: some View {
        ZStack {
            Color.black.edgesIgnoringSafeArea(.all)
            
            // Border animation path
            BorderAnimation(progress: progress)
                .stroke(Color.blue, lineWidth: 10)
                .edgesIgnoringSafeArea(.all)
                .mask(
                    RoundedRectangle(cornerRadius: UIScreen.main.displayCornerRadius)
                        .edgesIgnoringSafeArea(.all)
                )
            
            VStack(spacing: 24) {
                // App Icon - using the correct asset name
//              let image = UIImage(named: "AppIcon")!
                Image("Icon-1024")
                    .resizable()
                    .frame(width: 80, height: 80)
                    .cornerRadius(16)
                    .shadow(color: .blue.opacity(0.3), radius: 10)
                
                VStack(spacing: 12) {
                    Text("SightLine")
                        .font(.custom("Baskerville", size: 24))
                        .fontWeight(.medium)
                        .foregroundColor(.white)
                }
            }
        }
        .opacity(opacity)
        .onAppear {
            withAnimation(.linear(duration: 2).repeatForever(autoreverses: false)) {
                progress = 1.0
            }
            
            DispatchQueue.main.asyncAfter(deadline: .now() + 3) {
                withAnimation(.easeOut(duration: 0.5)) {
                    opacity = 0
                }
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    onFinished()
                }
            }
        }
    }
}

extension UIScreen {
    var displayCornerRadius: CGFloat {
        let key = "_displayCornerRadius"
        if let val = self.value(forKey: key) as? CGFloat {
            return val
        }
        return 39
    }
}

struct BorderAnimation: Shape {
    var progress: CGFloat
    
    var animatableData: CGFloat {
        get { progress }
        set { progress = newValue }
    }
    
    func path(in rect: CGRect) -> Path {
        let cornerRadius = UIScreen.main.displayCornerRadius
        
        // Create the full rounded rectangle path
        let roundedRect = Path { path in
            path.move(to: CGPoint(x: rect.minX + cornerRadius, y: rect.minY))
            
            // Top edge and top-right corner
            path.addLine(to: CGPoint(x: rect.maxX - cornerRadius, y: rect.minY))
            path.addArc(
                center: CGPoint(x: rect.maxX - cornerRadius, y: rect.minY + cornerRadius),
                radius: cornerRadius,
                startAngle: Angle(degrees: -90),
                endAngle: Angle(degrees: 0),
                clockwise: false
            )
            
            // Right edge and bottom-right corner
            path.addLine(to: CGPoint(x: rect.maxX, y: rect.maxY - cornerRadius))
            path.addArc(
                center: CGPoint(x: rect.maxX - cornerRadius, y: rect.maxY - cornerRadius),
                radius: cornerRadius,
                startAngle: Angle(degrees: 0),
                endAngle: Angle(degrees: 90),
                clockwise: false
            )
            
            // Bottom edge and bottom-left corner
            path.addLine(to: CGPoint(x: rect.minX + cornerRadius, y: rect.maxY))
            path.addArc(
                center: CGPoint(x: rect.minX + cornerRadius, y: rect.maxY - cornerRadius),
                radius: cornerRadius,
                startAngle: Angle(degrees: 90),
                endAngle: Angle(degrees: 180),
                clockwise: false
            )
            
            // Left edge and top-left corner
            path.addLine(to: CGPoint(x: rect.minX, y: rect.minY + cornerRadius))
            path.addArc(
                center: CGPoint(x: rect.minX + cornerRadius, y: rect.minY + cornerRadius),
                radius: cornerRadius,
                startAngle: Angle(degrees: 180),
                endAngle: Angle(degrees: 270),
                clockwise: false
            )
        }
        
        // Trim the path based on progress
        return roundedRect.trimmedPath(from: 0, to: progress)
    }
}

// Preview
struct SplashView_Previews: PreviewProvider {
    static var previews: some View {
        SplashView {
            print("Splash finished")
        }
        .previewDisplayName("Splash Screen")
    }
}

================
File: sightline/sightline/Views/VerticalFeedView.swift
================
import SwiftUI
import UIKit

struct VerticalFeedView<Content: View>: UIViewControllerRepresentable {
    let content: (Int) -> Content
    @Binding var currentIndex: Int
    let itemCount: Int
    let onIndexChanged: (Int) -> Void
    
    init(currentIndex: Binding<Int>, 
         itemCount: Int,
         onIndexChanged: @escaping (Int) -> Void,
         @ViewBuilder content: @escaping (Int) -> Content) {
        self.content = content
        self._currentIndex = currentIndex
        self.itemCount = itemCount
        self.onIndexChanged = onIndexChanged
    }
    
    func makeCoordinator() -> Coordinator {
        Coordinator(self)
    }
    
    func makeUIViewController(context: Context) -> UIPageViewController {
        let controller = UIPageViewController(
            transitionStyle: .scroll,
            navigationOrientation: .vertical,
            options: [.interPageSpacing: 0]
        )
        controller.dataSource = context.coordinator
        controller.delegate = context.coordinator
        controller.view.backgroundColor = .black
        
        // Disable system gestures that might interfere
        controller.view.gestureRecognizers?.forEach { gesture in
            (gesture as? UIScreenEdgePanGestureRecognizer)?.isEnabled = false
        }
        
        // Set up the initial view controller
        let hostingController = context.coordinator.hostingController(for: currentIndex)
        controller.setViewControllers([hostingController], direction: .forward, animated: false)
        
        return controller
    }
    
    func updateUIViewController(_ uiViewController: UIPageViewController, context: Context) {
        // Handle external index changes
        if context.coordinator.currentIndex != currentIndex {
            let newVC = context.coordinator.hostingController(for: currentIndex)
            let direction: UIPageViewController.NavigationDirection = 
                context.coordinator.currentIndex > currentIndex ? .reverse : .forward
            
            // Use setViewControllers without animation for distant jumps
            let shouldAnimate = abs(context.coordinator.currentIndex - currentIndex) <= 1
            uiViewController.setViewControllers([newVC], direction: direction, animated: shouldAnimate)
            context.coordinator.currentIndex = currentIndex
        }
    }
    
    class Coordinator: NSObject, UIPageViewControllerDataSource, UIPageViewControllerDelegate {
        var parent: VerticalFeedView
        var currentIndex: Int
        var hostingControllers: [Int: UIHostingController<AnyView>] = [:]
        
        init(_ verticalFeedView: VerticalFeedView) {
            self.parent = verticalFeedView
            self.currentIndex = verticalFeedView.currentIndex
        }
        
        func hostingController(for index: Int) -> UIHostingController<AnyView> {
            if let existingController = hostingControllers[index] {
                return existingController
            }
            
            guard index >= 0 && index < parent.itemCount else {
                // Return an empty view controller if index is out of bounds
                let fallbackView = AnyView(Color.black)
                let fallbackController = UIHostingController(rootView: fallbackView)
                fallbackController.view.backgroundColor = .clear
                return fallbackController
            }
            
            let view = AnyView(
                parent.content(index)
                    .frame(maxWidth: .infinity, maxHeight: .infinity)
                    .background(Color.black)
            )
            
            let hostingController = UIHostingController(rootView: view)
            hostingController.view.backgroundColor = .clear
            hostingControllers[index] = hostingController
            
            cleanupDistantControllers(from: index)
            
            return hostingController
        }
        
        private func cleanupDistantControllers(from currentIndex: Int) {
            let keepRange = (currentIndex - 2)...(currentIndex + 2)
            hostingControllers = hostingControllers.filter { keepRange.contains($0.key) }
        }
        
        // MARK: - UIPageViewControllerDataSource
        
        func pageViewController(_ pageViewController: UIPageViewController, viewControllerBefore viewController: UIViewController) -> UIViewController? {
            let index = currentIndex - 1
            guard index >= 0 else { return nil }
            return hostingController(for: index)
        }
        
        func pageViewController(_ pageViewController: UIPageViewController, viewControllerAfter viewController: UIViewController) -> UIViewController? {
            let index = currentIndex + 1
            guard index < parent.itemCount else { return nil }
            return hostingController(for: index)
        }
        
        // MARK: - UIPageViewControllerDelegate
        
        func pageViewController(_ pageViewController: UIPageViewController, 
                              didFinishAnimating finished: Bool,
                              previousViewControllers: [UIViewController],
                              transitionCompleted completed: Bool) {
            guard completed,
                  let visibleViewController = pageViewController.viewControllers?.first,
                  let index = hostingControllers.first(where: { $0.value == visibleViewController })?.key
            else { return }
            
            currentIndex = index
            parent.onIndexChanged(index)
        }
    }
}

================
File: sightline/sightline/DebugGalleryView.swift
================
import SwiftUI

struct DebugGalleryView: View {
    let imageNames: [String]
    @StateObject private var viewModel: LandmarkDetectionViewModel
    
    init(imageNames: [String], appState: AppState) {
        self.imageNames = imageNames
        self._viewModel = StateObject(wrappedValue: LandmarkDetectionViewModel(appState: appState))
    }
    
    private let columns = [
        GridItem(.flexible()),
        GridItem(.flexible()),
        GridItem(.flexible())
    ]
    
    var body: some View {
        NavigationView {
            ScrollView {
                LazyVGrid(columns: columns, spacing: 16) {
                    ForEach(imageNames, id: \.self) { imageName in
                        if let uiImage = UIImage(named: imageName) {
                            Image(uiImage: uiImage)
                                .resizable()
                                .scaledToFill()
                                .frame(width: 100, height: 100)
                                .clipped()
                                .cornerRadius(8)
                                .overlay(
                                    viewModel.isLoading ?
                                    ProgressView()
                                        .background(Color.black.opacity(0.3))
                                    : nil
                                )
                                .onTapGesture {
                                    Task {
                                        await viewModel.detectLandmark(for: uiImage)
                                    }
                                }
                        } else {
                            RoundedRectangle(cornerRadius: 8)
                                .fill(Color.gray)
                                .frame(width: 100, height: 100)
                                .overlay(Text("No Image")
                                    .foregroundColor(.white)
                                    .font(.caption)
                                )
                        }
                    }
                }
                .padding()
            }
            .navigationTitle("Debug Landmark Detection")
            .navigationBarTitleDisplayMode(.inline)
            
            if let landmark = viewModel.detectedLandmark {
                LandmarkDetailView(landmark: landmark)
            }
        }
    }
}

struct DebugGalleryView_Previews: PreviewProvider {
    static var previews: some View {
        DebugGalleryView(
            imageNames: ["utcapitol1", "utcapitol2", "ladybirdlake1"],
            appState: AppState()
        )
    }
}

================
File: sightline/sightline/LandmarkDetection.swift
================
import SwiftUI
import FirebaseAuth
import FirebaseFirestore
import FirebaseFunctions
import UIKit

// Add this struct to model the landmark data
struct LandmarkInfo: Identifiable {
    let id = UUID()
    let name: String
    let description: String?
    let detailedDescription: String?
    let websiteUrl: String?
    let imageUrl: String?
    let latitude: Double?
    let longitude: Double?
    let neighborhood: Neighborhood?
    
    init(name: String, knowledgeGraphData: [String: Any]?, locationData: [[String: Any]]?, neighborhoodData: [String: Any]?) {
        self.name = name
        self.description = knowledgeGraphData?["description"] as? String
        self.detailedDescription = (knowledgeGraphData?["detailedDescription"] as? [String: Any])?["articleBody"] as? String
        self.websiteUrl = (knowledgeGraphData?["url"] as? String)
        self.imageUrl = (knowledgeGraphData?["image"] as? [String: Any])?["contentUrl"] as? String
        
        if let firstLocation = (locationData?.first),
           let latLng = firstLocation["latLng"] as? [String: Any] {
            self.latitude = latLng["latitude"] as? Double
            self.longitude = latLng["longitude"] as? Double
        } else {
            self.latitude = nil
            self.longitude = nil
        }
        
        if let neighborhoodData = neighborhoodData {
            // Create a Neighborhood manually from the dictionary
            let id = neighborhoodData["place_id"] as? String ?? ""
            let name = neighborhoodData["name"] as? String ?? ""
            let description = neighborhoodData["description"] as? String ?? ""
            let imageUrl = neighborhoodData["image_url"] as? String ?? ""
            let boundsData = neighborhoodData["bounds"] as? [String: Any] ?? [:]
            
            let neData = boundsData["northeast"] as? [String: Any] ?? [:]
            let swData = boundsData["southwest"] as? [String: Any] ?? [:]
            
            let bounds = Neighborhood.GeoBounds(
                northeast: Neighborhood.GeoBounds.Point(
                    lat: neData["lat"] as? Double ?? 0,
                    lng: neData["lng"] as? Double ?? 0
                ),
                southwest: Neighborhood.GeoBounds.Point(
                    lat: swData["lat"] as? Double ?? 0,
                    lng: swData["lng"] as? Double ?? 0
                )
            )
            
            self.neighborhood = Neighborhood(
                id: id,
                name: name,
                description: description,
                imageUrl: imageUrl,
                bounds: bounds,
                landmarks: nil  // We'll get landmarks when we fetch the full neighborhood
            )
        } else {
            self.neighborhood = nil
        }
    }
}

class LandmarkDetectionViewModel: ObservableObject {
    @Published var selectedImage: UIImage?
    @Published var detectionResult: String = ""
    @Published var detectedLandmark: LandmarkInfo?
    @Published var unlockStatus: String = ""
    @Published var isLoading = false  // Add loading state
    
    let imageNames = ["utcapitol1", "utcapitol2", "ladybirdlake1"]
    private let services = ServiceContainer.shared  // Use services
    private lazy var functions = Functions.functions()
    private var appState: AppState
    
    init(appState: AppState) {
        self.appState = appState
    }
    
    func detectLandmark(for image: UIImage) async {
        await MainActor.run {
            isLoading = true
            detectionResult = ""
            detectedLandmark = nil
        }
        
        guard let imageData = image.jpegData(compressionQuality: 0.8) else {
            await MainActor.run {
                detectionResult = "Image conversion failed."
                isLoading = false
            }
            return
        }
        
        let base64String = imageData.base64EncodedString()
        let requestData: [String: Any] = [
            "image": ["content": base64String],
            "features": [
                ["maxResults": 1, "type": "LANDMARK_DETECTION"]
            ]
        ]
        
        do {
            let result = try await functions.httpsCallable("annotateImage").call(requestData)
            if let dict = result.data as? [String: Any],
               let landmarkData = dict["landmark"] as? [String: Any] {
                
                let landmarkName = landmarkData["name"] as? String ?? "Unknown Landmark"
                let neighborhoodData = landmarkData["neighborhood"] as? [String: Any]
                
                let landmark = LandmarkInfo(
                    name: landmarkName,
                    knowledgeGraphData: nil,
                    locationData: landmarkData["locations"] as? [[String: Any]],
                    neighborhoodData: neighborhoodData
                )
                
                await MainActor.run {
                    detectedLandmark = landmark
                }
                
                // Handle neighborhood unlock
                await handleNeighborhoodUnlock(landmark: landmark)
                
            } else {
                await MainActor.run {
                    detectionResult = "No landmarks detected."
                }
            }
        } catch {
            await MainActor.run {
                detectionResult = "Error: \(error.localizedDescription)"
            }
        }
        
        await MainActor.run {
            isLoading = false
        }
    }
    
    private func handleDetectionResult(_ data: Any) {
        guard let dict = data as? [String: Any] else {
            handleError("Invalid response format")
            return
        }
        
        guard let landmarkData = dict["landmark"] as? [String: Any],
              let landmarkName = landmarkData["name"] as? String else {
            detectionResult = "No landmarks detected."
            isLoading = false
            return
        }
        
        let neighborhoodData = landmarkData["neighborhood"] as? [String: Any]
        
        let landmark = LandmarkInfo(
            name: landmarkName,
            knowledgeGraphData: landmarkData["knowledgeGraph"] as? [String: Any],
            locationData: landmarkData["locations"] as? [[String: Any]],
            neighborhoodData: neighborhoodData
        )
        
        detectionResult = landmarkName
        detectedLandmark = landmark
        
        // Handle neighborhood unlock in background
        Task {
            await handleNeighborhoodUnlock(landmark: landmark)
        }
    }
    
    private func handleError(_ message: String) {
        detectionResult = "Error: \(message)"
        print("Detection error: \(message)")
        isLoading = false
    }
    
    private func handleNeighborhoodUnlock(landmark: LandmarkInfo) async {
        guard let neighborhood = landmark.neighborhood else {
            await MainActor.run {
                unlockStatus = "No neighborhood found for this landmark"
            }
            return
        }
        
        guard let neighborhoodId = neighborhood.id else {
            await MainActor.run {
                unlockStatus = "Invalid neighborhood ID"
            }
            return
        }
        
    }
    
    func updateAppState(_ newAppState: AppState) {
        self.appState = newAppState
    }
}

// New view for displaying landmark details
struct LandmarkDetailView: View {
    let landmark: LandmarkInfo
    
    var body: some View {
        ScrollView {
            VStack(alignment: .leading, spacing: 16) {
                if let imageUrl = landmark.imageUrl,
                   let url = URL(string: imageUrl) {
                    AsyncImage(url: url) { image in
                        image
                            .resizable()
                            .scaledToFit()
                    } placeholder: {
                        ProgressView()
                    }
                    .frame(maxHeight: 300)
                }
                
                VStack(alignment: .leading, spacing: 12) {
                    Text(landmark.name)
                        .font(.title)
                        .bold()
                    
                    if let description = landmark.description {
                        Text(description)
                            .font(.subheadline)
                    }
                    
                    if let detailedDescription = landmark.detailedDescription {
                        Text(detailedDescription)
                            .font(.body)
                            .padding(.top, 8)
                    }
                    
                    if let websiteUrl = landmark.websiteUrl,
                       let url = URL(string: websiteUrl) {
                        Link("Visit Website", destination: url)
                            .padding(.top, 8)
                    }
                    
                    if let lat = landmark.latitude,
                       let lon = landmark.longitude {
                        Text("Location: \(lat), \(lon)")
                            .font(.caption)
                            .padding(.top, 8)
                    }
                }
                .padding()
            }
        }
        .navigationBarTitleDisplayMode(.inline)
    }
}

struct LandmarkDetectionView: View {
    @EnvironmentObject var appState: AppState
    @StateObject private var viewModel = LandmarkDetectionViewModel(appState: AppState())
    
    // Camera/transition states
    @State private var isCameraMode = false
    @State private var navigateToLandmark: LandmarkInfo? = nil
    @State private var showTransition: Bool = false
    @State private var shouldFlash = false
    @State private var fadeToBlack = false
    @State private var showingGalleryPicker = false
    
    @Namespace private var scanningNamespace
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // Background Image - adjust position and offset
                Image("discoverbg")
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: geometry.size.width, height: geometry.size.height + 100) // Make image taller
                    .clipped()
                
                // Status bar blur overlay
                Rectangle()
                    .fill(.ultraThinMaterial)
                    .frame(height: geometry.safeAreaInsets.top)
                    .ignoresSafeArea()
                
                if isCameraMode {
                    // Camera View
                    CameraView(
                      onFrameCaptured: { image in
                        Task {
                          await viewModel.detectLandmark(for: image)
                          if let landmark = viewModel.detectedLandmark {
                            await animateLandmarkDetectionFlow(landmark: landmark)
                          }
                        }
                      },
                      shouldFlash: $shouldFlash
                    )
                    
                    
                    // Close Button - now respecting safe area
                    VStack {
                      HStack {
                        Button(action: {
                          isCameraMode = false
                        }) {
                          Image(systemName: "xmark")
                            .font(.title2)
                            .foregroundColor(.white)
                            .padding(12)
                            .background(.ultraThinMaterial)
                            .clipShape(Circle())
                        }
                        .padding(.leading)
                        Spacer()
                      }
                      .padding(.top, geometry.safeAreaInsets.top + 40)
                      Spacer()
                    }
                    
                    // Scanning animations
                    if showTransition {
                      ScanningTransitionView(namespace: scanningNamespace)
                        .ignoresSafeArea()
                    } else {
                      ScanningAnimation(namespace: scanningNamespace)
                        .ignoresSafeArea()
                    }
                    
                    // Error messages
                    if viewModel.detectionResult.contains("Error") {
                      VStack {
                        Spacer()
                        Text(viewModel.detectionResult)
                          .foregroundColor(.white)
                          .padding()
                          .background(.black.opacity(0.6))
                          .cornerRadius(10)
                          .padding(.bottom, 30)
                      }
                    }
                    
                    // Fade-out overlay
                    Color.black
                      .opacity(fadeToBlack ? 1.0 : 0.0)
                      .ignoresSafeArea()
                } else {
                    // Main content - center in available space
                    ScrollView {
                        GeometryReader { scrollGeometry in
                            // Center the content both vertically and horizontally
                            VStack {
                              Spacer(minLength:800)
                                
                                // Content Container
                                VStack(spacing: 16) {
                                    Image(systemName: "camera.viewfinder")
                                        .font(.system(size: 64))
                                        .foregroundColor(Color(.systemYellow))
                                    
                                    Text("Discover Your City")
                                        .font(.custom("Baskerville-Bold", size: 32))
                                        .multilineTextAlignment(.center)
                                        .fixedSize(horizontal: false, vertical: true)
                                        .frame(maxWidth: .infinity)
                                        .padding(.horizontal, 24)
                                    
                                    Text("Capture landmarks to unlock neighborhood content and explore local stories")
                                        .font(.custom("Baskerville", size: 20))
                                        .foregroundColor(.white)
                                        .multilineTextAlignment(.center)
                                        .fixedSize(horizontal: false, vertical: true)
                                        .frame(maxWidth: .infinity)
                                        .padding(.horizontal, 24)
                                    
                                    Button(action: {
                                        isCameraMode = true
                                    }) {
                                        HStack(spacing: 12) {
                                            Image(systemName: "camera.fill")
                                                .font(.title3)
                                            Text("Open Camera")
                                                .font(.title3)
                                        }
                                        .foregroundColor(.black)
                                        .frame(maxWidth: .infinity)
                                        .padding(.vertical, 16)
                                        .background(Color(.systemYellow))
                                        .cornerRadius(12)
                                    }
                                    .padding(.top, 12)
                                }
                                .padding(24)
                                .background(.ultraThinMaterial)
                                .cornerRadius(16)
                                .shadow(radius: 8)
                                .padding()
                                
                                Spacer(minLength: 0)
                            }
                            .frame(
                                minWidth: scrollGeometry.size.width,
                                minHeight: scrollGeometry.size.height
                            )
                        }
                    }
                }
                
#if DEBUG
                // Debug Gallery Button
                VStack {
                  Spacer()
                  HStack {
                    Spacer()
                    Button(action: {
                      showingGalleryPicker = true
                    }) {
                      Image(systemName: "photo.stack")
                        .font(.title2)
                        .foregroundColor(.white)
                        .padding(12)
                        .background(.ultraThinMaterial)
                        .clipShape(Circle())
                    }
                    .padding(.trailing, 16)
                    .padding(.bottom, 160)
                  }
                }
#endif
            }
                
            // Navigation link for landmark detail
            if let landmark = navigateToLandmark {
                NavigationLink(
                    destination: LandmarkDetailView(landmark: landmark),
                    isActive: Binding(
                        get: { navigateToLandmark != nil },
                        set: { if !$0 { navigateToLandmark = nil } }
                    )
                ) {
                    EmptyView()
                }
            }
        }
        .ignoresSafeArea(.container, edges: [.top]) // Only ignore top safe area
        .sheet(isPresented: $showingGalleryPicker) {
            NavigationView {
                ScrollView {
                    LazyVGrid(columns: [
                        GridItem(.flexible()),
                        GridItem(.flexible()),
                        GridItem(.flexible())
                    ], spacing: 8) {
                        ForEach(viewModel.imageNames, id: \.self) { name in
                            Image(name)
                                .resizable()
                                .aspectRatio(contentMode: .fill)
                                .frame(height: 120)
                                .clipShape(RoundedRectangle(cornerRadius: 8))
                                .onTapGesture {
                                    if let uiImage = UIImage(named: name) {
                                        viewModel.selectedImage = uiImage
                                        Task {
                                            await viewModel.detectLandmark(for: uiImage)
                                        }
                                        showingGalleryPicker = false
                                    }
                                }
                        }
                    }
                    .padding()
                }
                .navigationTitle("Debug Gallery")
                .navigationBarTitleDisplayMode(.inline)
                .toolbar {
                    ToolbarItem(placement: .navigationBarTrailing) {
                        Button("Done") {
                            showingGalleryPicker = false
                        }
                    }
                }
            }
        }
        .onAppear {
            viewModel.updateAppState(appState)
        }
    }
    
    /// Single flow that coordinates flash, scanning lines, fade, then the detail view.
    private func animateLandmarkDetectionFlow(landmark: LandmarkInfo) async {
        // 1) Trigger camera flash
        withAnimation(.easeIn(duration: 0.1)) {
            shouldFlash = true
        }
        
        // 2) Short delay so flash is visible
        try? await Task.sleep(nanoseconds: 150_000_000) // 0.15s
        
        // 3) Run scanning transition
        withAnimation(.easeInOut(duration: 1.0)) {
            showTransition = true
        }
        
        // 4) Wait for scanning line to expand
        try? await Task.sleep(nanoseconds: 1_000_000_000) // 1s
        
        // 5) Fade to black
        withAnimation(.easeIn(duration: 0.5)) {
            fadeToBlack = true
        }
        
        // 6) Wait for fade
        try? await Task.sleep(nanoseconds: 500_000_000) // 0.5s
        
        // 7) Switch to feed tab
        appState.shouldSwitchToFeed = true
        
        // 8) Switch out of camera mode
        isCameraMode = false
        
        // 9) Reset animations
        showTransition = false
        fadeToBlack = false
        shouldFlash = false
    }
}

struct LandmarkDetectionView_Previews: PreviewProvider {
    static var previews: some View {
        let previewAppState = AppState()
        LandmarkDetectionView()
            .environmentObject(previewAppState)
    }
}

================
File: sightline/sightline/sightlineApp.swift
================
import SwiftUI
import FirebaseCore
// Make sure SplashView is accessible
import FirebaseAuth

@main
struct SightlineApp: App {
    @StateObject private var appState = AppState()
    @StateObject private var appViewModel = AppViewModel()
    @State private var showingSplash = true
    
    init() {
        // Configure Firebase when the app starts.
        FirebaseApp.configure()
    }

    var body: some Scene {
        WindowGroup {
            ZStack {
                MainTabView()
                    .environmentObject(appState)
                    .task {
                        // First sign in
                        do {
                            try await ServiceContainer.shared.auth.signInAnonymously()
                            // Then preload data
                            await appViewModel.preloadAppData()
                            // Only hide splash after preloading is done
                            withAnimation {
                                showingSplash = false
                            }
                        } catch {
                            print("Failed to initialize app: \(error)")
                            // Maybe show error state in splash screen
                            showingSplash = false
                        }
                    }
                
                if showingSplash {
                    SplashView {
                        // Empty closure since we're handling dismiss in task
                    }
                    .transition(.opacity)
                }
            }
        }
    }
}

================
File: sightline/sightline.xcodeproj/xcuserdata/chrissutton.xcuserdatad/xcdebugger/Breakpoints_v2.xcbkptlist
================
<?xml version="1.0" encoding="UTF-8"?>
<Bucket
   uuid = "D2849DC8-FDC9-410B-B0D8-E42151764F8C"
   type = "1"
   version = "2.0">
</Bucket>

================
File: sightline/sightline.xcodeproj/xcuserdata/chrissutton.xcuserdatad/xcschemes/xcschememanagement.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>SchemeUserState</key>
	<dict>
		<key>sightline.xcscheme_^#shared#^_</key>
		<dict>
			<key>orderHint</key>
			<integer>0</integer>
		</dict>
	</dict>
</dict>
</plist>

================
File: sightline/sightlineTests/sightlineTests.swift
================
//
//  sightlineTests.swift
//  sightlineTests
//
//  Created by Chris Sutton on 2/4/25.
//

import Testing
@testable import sightline

struct sightlineTests {

    @Test func example() async throws {
        // Write your test here and use APIs like `#expect(...)` to check expected conditions.
    }

}

================
File: sightline/sightlineUITests/sightlineUITests.swift
================
//
//  sightlineUITests.swift
//  sightlineUITests
//
//  Created by Chris Sutton on 2/4/25.
//

import XCTest

final class sightlineUITests: XCTestCase {

    override func setUpWithError() throws {
        // Put setup code here. This method is called before the invocation of each test method in the class.

        // In UI tests it is usually best to stop immediately when a failure occurs.
        continueAfterFailure = false

        // In UI tests it’s important to set the initial state - such as interface orientation - required for your tests before they run. The setUp method is a good place to do this.
    }

    override func tearDownWithError() throws {
        // Put teardown code here. This method is called after the invocation of each test method in the class.
    }

    @MainActor
    func testExample() throws {
        // UI tests must launch the application that they test.
        let app = XCUIApplication()
        app.launch()

        // Use XCTAssert and related functions to verify your tests produce the correct results.
    }

    @MainActor
    func testLaunchPerformance() throws {
        if #available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 7.0, *) {
            // This measures how long it takes to launch your application.
            measure(metrics: [XCTApplicationLaunchMetric()]) {
                XCUIApplication().launch()
            }
        }
    }
}

================
File: sightline/sightlineUITests/sightlineUITestsLaunchTests.swift
================
//
//  sightlineUITestsLaunchTests.swift
//  sightlineUITests
//
//  Created by Chris Sutton on 2/4/25.
//

import XCTest

final class sightlineUITestsLaunchTests: XCTestCase {

    override class var runsForEachTargetApplicationUIConfiguration: Bool {
        true
    }

    override func setUpWithError() throws {
        continueAfterFailure = false
    }

    @MainActor
    func testLaunch() throws {
        let app = XCUIApplication()
        app.launch()

        // Insert steps here to perform after app launch but before taking a screenshot,
        // such as logging into a test account or navigating somewhere in the app

        let attachment = XCTAttachment(screenshot: app.screenshot())
        attachment.name = "Launch Screen"
        attachment.lifetime = .keepAlways
        add(attachment)
    }
}

================
File: .gitignore
================
# Firebase build and deployment files
/firebase-debug.log
/firebase-debug.*.log
.firebaserc

# Firebase Hosting
/firebase.json
*.cache
hosting/.cache

# Firebase Functions
/functions/node_modules/
/functions/.env
/functions/package-lock.json

# Firebase Emulators
/firebase-*.zip
/.firebase/
/emulator-ui/

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Environment files (local configs)
/.env.*
.DS_Store
.env.*

# Xcode
*.pbxproj
*.xcworkspace
*.xcuserdatadirectory
GoogleService-Info.plist

================
File: .markdownlint.json
================
{
  "MD013": false,
  "MD025": false,
  "MD033": false,
  "MD022": false,
  "MD032": false
}



================================================================
End of Codebase
================================================================
